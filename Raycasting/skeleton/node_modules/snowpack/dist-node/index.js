'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

function _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }

var colors = require('kleur/colors');
var path = _interopDefault(require('path'));
var util = _interopDefault(require('util'));
var yargs = _interopDefault(require('yargs-parser'));
var fs = require('fs');
var fs__default = _interopDefault(fs);
var got = _interopDefault(require('got'));
var rollupPluginAlias = _interopDefault(require('@rollup/plugin-alias'));
var rollupPluginCommonjs = _interopDefault(require('@rollup/plugin-commonjs'));
var rollupPluginJson = _interopDefault(require('@rollup/plugin-json'));
var rollupPluginNodeResolve = _interopDefault(require('@rollup/plugin-node-resolve'));
var rollupPluginNodePolyfills = _interopDefault(require('rollup-plugin-node-polyfills'));
var rollupPluginReplace = _interopDefault(require('@rollup/plugin-replace'));
var esModuleLexer = require('es-module-lexer');
var findUp = _interopDefault(require('find-up'));
var mkdirp = _interopDefault(require('mkdirp'));
var perf_hooks = require('perf_hooks');
var rimraf = _interopDefault(require('rimraf'));
var rollup = require('rollup');
var validatePackageName = _interopDefault(require('validate-npm-package-name'));
var cacache = _interopDefault(require('cacache'));
var PQueue = _interopDefault(require('p-queue'));
var globalCacheDir = _interopDefault(require('cachedir'));
var etag = _interopDefault(require('etag'));
var execa = _interopDefault(require('execa'));
var projectCacheDir = _interopDefault(require('find-cache-dir'));
var isbinaryfile = require('isbinaryfile');
var open = _interopDefault(require('open'));
var isNodeBuiltin = _interopDefault(require('is-builtin-module'));
var tar = _interopDefault(require('tar'));
var url = _interopDefault(require('url'));
var zlib = _interopDefault(require('zlib'));
var inject = _interopDefault(require('@rollup/plugin-inject'));
var glob = _interopDefault(require('glob'));
var stripComments = _interopDefault(require('strip-comments'));
var merge = require('deepmerge');
var merge__default = _interopDefault(merge);
var buildScriptPlugin = _interopDefault(require('@snowpack/plugin-build-script'));
var runScriptPlugin = _interopDefault(require('@snowpack/plugin-run-script'));
var cosmiconfig = require('cosmiconfig');
var jsonschema = require('jsonschema');
var esbuild = require('esbuild');
var WebSocket = _interopDefault(require('ws'));
var isCompressible = _interopDefault(require('compressible'));
var events = require('events');
var http = _interopDefault(require('http'));
var HttpProxy = _interopDefault(require('http-proxy'));
var http2 = _interopDefault(require('http2'));
var https = _interopDefault(require('https'));
var mime = _interopDefault(require('mime-types'));
var os = _interopDefault(require('os'));
var onProcessExit = _interopDefault(require('signal-exit'));
var stream = _interopDefault(require('stream'));
var detectPort = _interopDefault(require('detect-port'));
var readline = _interopDefault(require('readline'));

function _defineProperty(obj, key, value) {
  if (key in obj) {
    Object.defineProperty(obj, key, {
      value: value,
      enumerable: true,
      configurable: true,
      writable: true
    });
  } else {
    obj[key] = value;
  }

  return obj;
}

function ownKeys(object, enumerableOnly) {
  var keys = Object.keys(object);

  if (Object.getOwnPropertySymbols) {
    var symbols = Object.getOwnPropertySymbols(object);
    if (enumerableOnly) symbols = symbols.filter(function (sym) {
      return Object.getOwnPropertyDescriptor(object, sym).enumerable;
    });
    keys.push.apply(keys, symbols);
  }

  return keys;
}

function _objectSpread2(target) {
  for (var i = 1; i < arguments.length; i++) {
    var source = arguments[i] != null ? arguments[i] : {};

    if (i % 2) {
      ownKeys(Object(source), true).forEach(function (key) {
        _defineProperty(target, key, source[key]);
      });
    } else if (Object.getOwnPropertyDescriptors) {
      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));
    } else {
      ownKeys(Object(source)).forEach(function (key) {
        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));
      });
    }
  }

  return target;
}

function _objectWithoutPropertiesLoose(source, excluded) {
  if (source == null) return {};
  var target = {};
  var sourceKeys = Object.keys(source);
  var key, i;

  for (i = 0; i < sourceKeys.length; i++) {
    key = sourceKeys[i];
    if (excluded.indexOf(key) >= 0) continue;
    target[key] = source[key];
  }

  return target;
}

function _objectWithoutProperties(source, excluded) {
  if (source == null) return {};

  var target = _objectWithoutPropertiesLoose(source, excluded);

  var key, i;

  if (Object.getOwnPropertySymbols) {
    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);

    for (i = 0; i < sourceSymbolKeys.length; i++) {
      key = sourceSymbolKeys[i];
      if (excluded.indexOf(key) >= 0) continue;
      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;
      target[key] = source[key];
    }
  }

  return target;
}

const levels = {
  debug: 20,
  info: 30,
  warn: 40,
  error: 50,
  silent: 90
};
/** Custom logger heavily-inspired by https://github.com/pinojs/pino with extra features like log retentian */

class SnowpackLogger {
  constructor() {
    /** set the log level (can be changed after init) */
    this.level = 'info';
    /** configure maximum number of logs to keep (default: 500) */

    this.logCount = 500;
    this.history = []; // this is immutable; must be accessed with Logger.getHistory()

    this.callbacks = {
      debug: message => {
        console.log(message);
      },
      info: message => {
        console.log(message);
      },
      warn: message => {
        console.warn(message);
      },
      error: message => {
        console.error(message);
      }
    };
  }

  log({
    level,
    name,
    message
  }) {
    // test if this level is enabled or not
    if (levels[this.level] > levels[level]) {
      return; // do nothing
    } // format


    let text = message;
    if (level === 'warn') text = colors.yellow(text);
    if (level === 'error') text = colors.red(text);
    const log = `${colors.dim(`[${name}]`)} ${text}`; // add to log history and remove old logs to keep memory low

    this.history.push(log);

    while (this.history.length > this.logCount) {
      this.history.shift();
    } // log


    if (typeof this.callbacks[level] === 'function') {
      this.callbacks[level](log);
    } else {
      throw new Error(`No logging method defined for ${level}`);
    }
  }
  /** emit messages only visible when --debug is passed */


  debug(message, options) {
    const name = options && options.name || 'snowpack';
    this.log({
      level: 'debug',
      name,
      message
    });
  }
  /** emit general info */


  info(message, options) {
    const name = options && options.name || 'snowpack';
    this.log({
      level: 'info',
      name,
      message
    });
  }
  /** emit non-fatal warnings */


  warn(message, options) {
    const name = options && options.name || 'snowpack';
    this.log({
      level: 'warn',
      name,
      message
    });
  }
  /** emit critical error messages */


  error(message, options) {
    const name = options && options.name || 'snowpack';
    this.log({
      level: 'error',
      name,
      message
    });
  }
  /** get full logging history */


  getHistory() {
    return this.history;
  }
  /** listen for events */


  on(event, callback) {
    this.callbacks[event] = callback;
  }

}
/** export one logger to rest of app */


const logger = new SnowpackLogger();

const PIKA_CDN = `https://cdn.pika.dev`;
const GLOBAL_CACHE_DIR = globalCacheDir('snowpack'); // A note on cache naming/versioning: We currently version our global caches
// with the version of the last breaking change. This allows us to re-use the
// same cache across versions until something in the data structure changes.
// At that point, bump the version in the cache name to create a new unique
// cache name.

const RESOURCE_CACHE = path.join(GLOBAL_CACHE_DIR, 'pkg-cache-1.4');
const BUILD_CACHE = path.join(GLOBAL_CACHE_DIR, 'build-cache-2.7');
const PROJECT_CACHE_DIR = projectCacheDir({
  name: 'snowpack'
});
const DEV_DEPENDENCIES_DIR = path.join(PROJECT_CACHE_DIR, 'dev');
const LOCKFILE_HASH_FILE = '.hash';
const HAS_CDN_HASH_REGEX = /\-[a-zA-Z0-9]{16,}/; // NOTE(fks): Must match empty script elements to work properly.

const HTML_JS_REGEX = /(<script[\0-=\?-\uFFFF]*?type="module"[\s\S]*?>)([\s\S]*?)<\/script>/gim;
const CSS_REGEX = /@import[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*["']([\s\S]*?)["'];/g;
const SVELTE_VUE_REGEX = /(<script[\0-=\?-\uFFFF]*>)([\s\S]*?)<\/script>/gim;
const URL_HAS_PROTOCOL_REGEX = /^(\w+:)?\/\//;
/** Read file from disk; return a string if it’s a code file */

async function readFile(filepath) {
  const data = await fs__default.promises.readFile(filepath);
  const isBinary = await isbinaryfile.isBinaryFile(data);
  return isBinary ? data : data.toString('utf-8');
}
async function readLockfile(cwd) {
  try {
    var lockfileContents = fs__default.readFileSync(path.join(cwd, 'snowpack.lock.json'), {
      encoding: 'utf-8'
    });
  } catch (err) {
    // no lockfile found, ignore and continue
    return null;
  } // If this fails, we actually do want to alert the user by throwing


  return JSON.parse(lockfileContents);
}
async function writeLockfile(loc, importMap) {
  const sortedImportMap = {
    imports: {}
  };

  for (const key of Object.keys(importMap.imports).sort()) {
    sortedImportMap.imports[key] = importMap.imports[key];
  }

  fs__default.writeFileSync(loc, JSON.stringify(sortedImportMap, undefined, 2), {
    encoding: 'utf-8'
  });
}
function fetchCDNResource(resourceUrl, responseType) {
  if (!resourceUrl.startsWith(PIKA_CDN)) {
    resourceUrl = PIKA_CDN + resourceUrl;
  } // @ts-ignore - TS doesn't like responseType being unknown amount three options


  return got(resourceUrl, {
    responseType: responseType,
    headers: {
      'user-agent': `snowpack/v1.4 (https://snowpack.dev)`
    },
    throwHttpErrors: false
  });
}
function isTruthy(item) {
  return Boolean(item);
}
/** Get the package name + an entrypoint within that package (if given). */

function parsePackageImportSpecifier(imp) {
  const impParts = imp.split('/');

  if (imp.startsWith('@')) {
    const [scope, name, ...rest] = impParts;
    return [`${scope}/${name}`, rest.join('/') || null];
  }

  const [name, ...rest] = impParts;
  return [name, rest.join('/') || null];
}
/**
 * Given a package name, look for that package's package.json manifest.
 * Return both the manifest location (if believed to exist) and the
 * manifest itself (if found).
 *
 * NOTE: You used to be able to require() a package.json file directly,
 * but now with export map support in Node v13 that's no longer possible.
 */

function resolveDependencyManifest(dep, cwd) {
  // Attempt #1: Resolve the dependency manifest normally. This works for most
  // packages, but fails when the package defines an export map that doesn't
  // include a package.json. If we detect that to be the reason for failure,
  // move on to our custom implementation.
  try {
    const depManifest = fs__default.realpathSync.native(require.resolve(`${dep}/package.json`, {
      paths: [cwd]
    }));
    return [depManifest, require(depManifest)];
  } catch (err) {
    // if its an export map issue, move on to our manual resolver.
    if (err.code !== 'ERR_PACKAGE_PATH_NOT_EXPORTED') {
      return [null, null];
    }
  } // Attempt #2: Resolve the dependency manifest manually. This involves resolving
  // the dep itself to find the entrypoint file, and then haphazardly replacing the
  // file path within the package with a "./package.json" instead. It's not as
  // thorough as Attempt #1, but it should work well until export maps become more
  // established & move out of experimental mode.


  let result = [null, null];

  try {
    const fullPath = fs__default.realpathSync.native(require.resolve(dep, {
      paths: [cwd]
    })); // Strip everything after the package name to get the package root path
    // NOTE: This find-replace is very gross, replace with something like upath.

    const searchPath = `${path.sep}node_modules${path.sep}${dep.replace('/', path.sep)}`;
    const indexOfSearch = fullPath.lastIndexOf(searchPath);

    if (indexOfSearch >= 0) {
      const manifestPath = fullPath.substring(0, indexOfSearch + searchPath.length + 1) + 'package.json';
      result[0] = manifestPath;
      const manifestStr = fs__default.readFileSync(manifestPath, {
        encoding: 'utf-8'
      });
      result[1] = JSON.parse(manifestStr);
    }
  } catch (err) {// ignore
  } finally {
    return result;
  }
}
/**
 * If Rollup erred parsing a particular file, show suggestions based on its
 * file extension (note: lowercase is fine).
 */

const MISSING_PLUGIN_SUGGESTIONS = {
  '.svelte': 'Try installing rollup-plugin-svelte and adding it to Snowpack (https://www.snowpack.dev/#custom-rollup-plugins)',
  '.vue': 'Try installing rollup-plugin-vue and adding it to Snowpack (https://www.snowpack.dev/#custom-rollup-plugins)'
};
const appNames = {
  win32: {
    brave: 'brave',
    chrome: 'chrome'
  },
  darwin: {
    brave: 'Brave Browser',
    chrome: 'Google Chrome'
  },
  linux: {
    brave: 'brave',
    chrome: 'google-chrome'
  }
};
async function openInBrowser(protocol, hostname, port, browser) {
  const url = `${protocol}//${hostname}:${port}`;
  browser = /chrome/i.test(browser) ? appNames[process.platform]['chrome'] : /brave/i.test(browser) ? appNames[process.platform]['brave'] : browser;
  const isMac = process.platform === 'darwin';
  const isOpeningInChrome = /chrome|default/i.test(browser);

  if (isMac && isOpeningInChrome) {
    // If we're on macOS, and we haven't requested a specific browser,
    // we can try opening Chrome with AppleScript. This lets us reuse an
    // existing tab when possible instead of creating a new one.
    try {
      // see if Chrome process is open; fail if not
      await execa.command('ps cax | grep "Google Chrome"', {
        shell: true
      }); // use open Chrome tab if exists; create new Chrome tab if not

      const openChrome = execa('osascript ../assets/openChrome.applescript "' + encodeURI(url) + '"', {
        cwd: __dirname,
        stdio: 'ignore',
        shell: true
      }); // if Chrome doesn’t respond within 3s, fall back to opening new tab in default browser

      let isChromeStalled = setTimeout(() => {
        openChrome.cancel();
      }, 3000);

      try {
        await openChrome;
      } catch (err) {
        if (err.isCanceled) {
          console.warn(`Chrome not responding to Snowpack after 3s. Opening dev server in new tab.`);
        } else {
          console.error(err.toString() || err);
        }

        open(url);
      } finally {
        clearTimeout(isChromeStalled);
      }

      return true;
    } catch (err) {
      // if no open Chrome process, open default browser
      // no error message needed here
      open(url);
    }
  } else {
    browser === 'default' ? open(url) : open(url, {
      app: browser
    });
  }
}
async function checkLockfileHash(dir) {
  const lockfileLoc = await findUp(['package-lock.json', 'yarn.lock']);

  if (!lockfileLoc) {
    return true;
  }

  const hashLoc = path.join(dir, LOCKFILE_HASH_FILE);
  const newLockHash = etag(await fs__default.promises.readFile(lockfileLoc, 'utf-8'));
  const oldLockHash = await fs__default.promises.readFile(hashLoc, 'utf-8').catch(() => '');
  return newLockHash === oldLockHash;
}
async function updateLockfileHash(dir) {
  const lockfileLoc = await findUp(['package-lock.json', 'yarn.lock']);

  if (!lockfileLoc) {
    return;
  }

  const hashLoc = path.join(dir, LOCKFILE_HASH_FILE);
  const newLockHash = etag(await fs__default.promises.readFile(lockfileLoc));
  await mkdirp(path.dirname(hashLoc));
  await fs__default.promises.writeFile(hashLoc, newLockHash);
}
async function clearCache() {
  return Promise.all([cacache.rm.all(RESOURCE_CACHE), cacache.rm.all(BUILD_CACHE), rimraf.sync(PROJECT_CACHE_DIR)]);
}
/**
 * For the given import specifier, return an alias entry if one is matched.
 */

function findMatchingAliasEntry(config, spec) {
  // Only match bare module specifiers. relative and absolute imports should not match
  if (spec === '.' || spec === '..' || spec.startsWith('./') || spec.startsWith('../') || spec.startsWith('/') || spec.startsWith('http://') || spec.startsWith('https://')) {
    return undefined;
  }

  for (const [from, to] of Object.entries(config.alias)) {
    let foundType = isPackageAliasEntry(to) ? 'package' : 'path';
    const isExactMatch = spec === removeTrailingSlash(from);
    const isDeepMatch = spec.startsWith(addTrailingSlash(from));

    if (isExactMatch || isDeepMatch) {
      return {
        from,
        to,
        type: foundType
      };
    }
  }
}
/**
 * For the given import specifier, return an alias entry if one is matched.
 */

function isPackageAliasEntry(val) {
  return !path.isAbsolute(val);
}
/** Get full extensions of files */

function getExt(fileName) {
  return {
    /** base extension (e.g. `.js`) */
    baseExt: path.extname(fileName).toLocaleLowerCase(),

    /** full extension, if applicable (e.g. `.proxy.js`) */
    expandedExt: path.basename(fileName).replace(/[^.]+/, '').toLocaleLowerCase()
  };
}
/** Replace file extensions */

function replaceExt(fileName, oldExt, newExt) {
  const extToReplace = new RegExp(`\\${oldExt}$`, 'i');
  return fileName.replace(extToReplace, newExt);
}
/**
 * Sanitizes npm packages that end in .js (e.g `tippy.js` -> `tippyjs`).
 * This is necessary because Snowpack can’t create both a file and directory
 * that end in .js.
 */

function sanitizePackageName(filepath) {
  const dirs = filepath.split('/');
  const file = dirs.pop();
  return [...dirs.map(path => path.replace(/\.js$/i, 'js')), file].join('/');
} // Source Map spec v3: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.lmz475t4mvbx

/** CSS sourceMappingURL */

function cssSourceMappingURL(code, sourceMappingURL) {
  return code + `/*# sourceMappingURL=${sourceMappingURL} */`;
}
/** JS sourceMappingURL */

function jsSourceMappingURL(code, sourceMappingURL) {
  return code.replace(/\n*$/, '') + `\n//# sourceMappingURL=${sourceMappingURL}\n`; // strip ending lines & append source map (with linebreaks for safety)
}
/**
 * Formats the snowpack dependency name from a "webDependencies" input value:
 * 2. Remove any ".js"/".mjs" extension (will be added automatically by Rollup)
 */

function getWebDependencyName(dep) {
  return validatePackageName(dep).validForNewPackages ? dep.replace(/\.js$/i, 'js') // if this is a top-level package ending in .js, replace with js (e.g. tippy.js -> tippyjs)
  : dep.replace(/\.m?js$/i, ''); // otherwise simply strip the extension (Rollup will resolve it)
}
/** URL relative */

function relativeURL(path1, path2) {
  let url = path.relative(path1, path2).replace(/\\/g, '/');

  if (!url.startsWith('./') && !url.startsWith('../')) {
    url = './' + url;
  }

  return url;
}
const CLOSING_BODY_TAG = /<\s*\/\s*body\s*>/gi;
/** Append HTML before closing </body> tag */

function appendHTMLToBody(doc, htmlToAdd) {
  const closingBodyMatch = doc.match(CLOSING_BODY_TAG); // if no <body> tag found, throw an error (we can’t load your app properly)

  if (!closingBodyMatch) {
    throw new Error(`No <body> tag found in HTML (this is needed to load your app):\n\n${doc}`);
  } // if multiple <body> tags found, also freak out


  if (closingBodyMatch.length > 1) {
    throw new Error(`Multiple <body> tags found in HTML (perhaps commented out?):\n\n${doc}`);
  }

  return doc.replace(closingBodyMatch[0], htmlToAdd + closingBodyMatch[0]);
}
/** Add / to beginning of string (but don’t double-up) */

function addLeadingSlash(path) {
  return path.replace(/^\/?/, '/');
}
/** Add / to the end of string (but don’t double-up) */

function addTrailingSlash(path) {
  return path.replace(/\/?$/, '/');
}
/** Remove \ and / from beginning of string */

function removeLeadingSlash(path) {
  return path.replace(/^[/\\]+/, '');
}
/** Remove \ and / from end of string */

function removeTrailingSlash(path) {
  return path.replace(/[/\\]+$/, '');
}
const HMR_CLIENT_CODE = fs__default.readFileSync(path.join(__dirname, '../assets/hmr.js'), 'utf-8');

/**
 * Given an install specifier, attempt to resolve it from the CDN.
 * If no lockfile exists or if the entry is not found in the lockfile, attempt to resolve
 * it from the CDN directly. Otherwise, use the URL found in the lockfile and attempt to
 * check the local cache first.
 *
 * All resolved URLs are populated into the local cache, where our internal Rollup engine
 * will load them from when it installs your dependencies to disk.
 */

async function resolveDependency(installSpecifier, packageSemver, lockfile, canRetry = true) {
  // Right now, the CDN is only for top-level JS packages. The CDN doesn't support CSS,
  // non-JS assets, and has limited support for deep package imports. Snowpack
  // will automatically fall-back any failed/not-found assets from local
  // node_modules/ instead.
  if (!validatePackageName(installSpecifier).validForNewPackages) {
    return null;
  } // Grab the installUrl from our lockfile if it exists, otherwise resolve it yourself.


  let installUrl;
  let installUrlType;

  if (lockfile && lockfile.imports[installSpecifier]) {
    installUrl = lockfile.imports[installSpecifier];
    installUrlType = 'pin';
  } else {
    if (packageSemver === 'latest') {
      logger.warn(`warn(${installSpecifier}): Not found in "dependencies". Using latest package version...`);
    }

    if (packageSemver.startsWith('npm:@reactesm') || packageSemver.startsWith('npm:@pika/react')) {
      logger.error(`React workaround packages no longer needed! Revert to the official React & React-DOM packages.`);
      process.exit(1);
    }

    if (packageSemver.includes(' ') || packageSemver.includes(':')) {
      logger.warn(`warn(${installSpecifier}): Can't fetch complex semver "${packageSemver}" from remote CDN.`);
      return null;
    }

    installUrlType = 'lookup';
    installUrl = `${PIKA_CDN}/${installSpecifier}@${packageSemver}`;
  } // Hashed CDN urls never change, so its safe to grab them directly from the local cache
  // without a network request.


  if (installUrlType === 'pin') {
    const cachedResult = await cacache.get.info(RESOURCE_CACHE, installUrl).catch(() => null);

    if (cachedResult) {
      if (cachedResult.metadata) {
        const {
          pinnedUrl
        } = cachedResult.metadata;
        return pinnedUrl;
      }
    }
  } // Otherwise, resolve from the CDN remotely.


  const {
    statusCode,
    headers,
    body
  } = await fetchCDNResource(installUrl);

  if (statusCode !== 200) {
    logger.warn(`Failed to resolve [${statusCode}]: ${installUrl} (${body})`);
    logger.warn(`Falling back to local copy...`);
    return null;
  }

  let importUrlPath = headers['x-import-url'];
  let pinnedUrlPath = headers['x-pinned-url'];
  const buildStatus = headers['x-import-status'];
  const typesUrlPath = headers['x-typescript-types'];
  const typesUrl = typesUrlPath && `${PIKA_CDN}${typesUrlPath}`;

  if (installUrlType === 'pin') {
    const pinnedUrl = installUrl;
    await cacache.put(RESOURCE_CACHE, pinnedUrl, body, {
      metadata: {
        pinnedUrl,
        typesUrl
      }
    });
    return pinnedUrl;
  }

  if (pinnedUrlPath) {
    const pinnedUrl = `${PIKA_CDN}${pinnedUrlPath}`;
    await cacache.put(RESOURCE_CACHE, pinnedUrl, body, {
      metadata: {
        pinnedUrl,
        typesUrl
      }
    });
    return pinnedUrl;
  }

  if (buildStatus === 'SUCCESS') {
    logger.warn(`Failed to lookup [${statusCode}]: ${installUrl}`);
    logger.warn(`Falling back to local copy...`);
    return null;
  }

  if (!canRetry || buildStatus === 'FAIL') {
    logger.warn(`Failed to build: ${installSpecifier}@${packageSemver}`);
    logger.warn(`Falling back to local copy...`);
    return null;
  }

  logger.info(colors.cyan(`Building ${installSpecifier}@${packageSemver}... (This takes a moment, but will be cached for future use)`));

  if (!importUrlPath) {
    logger.error('X-Import-URL header expected, but none received.');
    process.exit(1);
  }

  const {
    statusCode: lookupStatusCode
  } = await fetchCDNResource(importUrlPath);

  if (lookupStatusCode !== 200) {
    logger.error(`Unexpected response [${lookupStatusCode}]: ${PIKA_CDN}${importUrlPath}`);
    process.exit(1);
  }

  return resolveDependency(installSpecifier, packageSemver, lockfile, false);
}

async function resolveTargetsFromRemoteCDN(lockfile, config) {
  const downloadQueue = new PQueue({
    concurrency: 16
  });
  const newLockfile = {
    imports: {}
  };
  let resolutionError;

  for (const [installSpecifier, installSemver] of Object.entries(config.webDependencies)) {
    downloadQueue.add(async () => {
      try {
        const resolvedUrl = await resolveDependency(installSpecifier, installSemver, lockfile);

        if (resolvedUrl) {
          newLockfile.imports[installSpecifier] = resolvedUrl;
        }
      } catch (err) {
        resolutionError = resolutionError || err;
      }
    });
  }

  await downloadQueue.onIdle();

  if (resolutionError) {
    throw resolutionError;
  }

  return newLockfile;
}

/**
 * rollup-plugin-catch-unresolved
 *
 * Catch any unresolved imports to give proper warnings (Rollup default is to ignore).
 */

function rollupPluginCatchUnresolved() {
  return {
    name: 'snowpack:rollup-plugin-catch-unresolved',

    resolveId(id, importer) {
      // Ignore remote http/https imports
      if (id.startsWith('http://') || id.startsWith('https://')) {
        return false;
      }

      if (isNodeBuiltin(id)) {
        this.warn({
          id: importer,
          message: `Module "${id}" (Node.js built-in) is not available in the browser. Run Snowpack with --polyfill-node to fix.`
        });
      } else {
        this.warn({
          id: importer,
          message: `Module "${id}" could not be resolved by Snowpack (Is it installed?).`
        });
      }

      return false;
    }

  };
}

const FETCH_POLYFILL = `
// native patch for: node-fetch, whatwg-fetch
// ref: https://github.com/tc39/proposal-global
var getGlobal = function () {
  if (typeof self !== 'undefined') { return self; }
  if (typeof window !== 'undefined') { return window; }
  if (typeof global !== 'undefined') { return global; }
  throw new Error('unable to locate global object');
}
var global = getGlobal();
export default global.fetch.bind(global);
export const Headers = global.Headers;
export const Request = global.Request;
export const Response = global.Response;
`;
/**
 * rollup-plugin-catch-fetch
 *
 * How it works: NPM packages will sometimes contain Node.js-specific polyfills
 * for the native browser Fetch API. Since this makes no sense in an ESM web
 * project, we can replace these expensive polyfills with native references to
 * the fetch API.
 *
 * This still allows you to polyfill fetch in older browsers, if you desire.
 */

function isNodeFetch(id) {
  return id === 'node-fetch' || id === 'whatwg-fetch' || id.includes(path.join('node_modules', 'node-fetch')) || // note: sometimes Snowpack has found the entry file already
  id.includes(path.join('node_modules', 'whatwg-fetch'));
}

function rollupPluginCatchFetch() {
  return {
    name: 'snowpack:fetch-handler',

    resolveId(id) {
      return isNodeFetch(id) ? id : null;
    },

    load(id) {
      return isNodeFetch(id) ? FETCH_POLYFILL : null;
    }

  };
}

function getInjectorCode(name, code) {
  return `
/** SNOWPACK INJECT STYLE: ${name} */
function __snowpack__injectStyle(css) {
  const headEl = document.head || document.getElementsByTagName('head')[0];
  const styleEl = document.createElement('style');
  styleEl.type = 'text/css';
  if (styleEl.styleSheet) {
    styleEl.styleSheet.cssText = css;
  } else {
    styleEl.appendChild(document.createTextNode(css));
  }
  headEl.appendChild(styleEl);
}
__snowpack__injectStyle(${JSON.stringify(code)});\n`;
}
/**
 * rollup-plugin-css
 *
 * Support installing any imported CSS into your dependencies. This isn't strictly valid
 * ESM code, but it is popular in the npm ecosystem & web development ecosystems. It also
 * solves a problem that is difficult to solve otherwise (referencing CSS from JS) so for
 * those reasons we have added default support for importing CSS into Snowpack v2.
 */


function rollupPluginCss() {
  return {
    name: 'snowpack:rollup-plugin-css',

    resolveId(source, importer) {
      if (!source.endsWith('.css')) {
        return null;
      }

      return this.resolve(source, importer, {
        skipSelf: true
      }).then(resolved => {
        return resolved || null;
      });
    },

    async load(id) {
      if (!id.endsWith('.css')) {
        return null;
      }

      const code = await fs.promises.readFile(id, {
        encoding: 'utf-8'
      });
      const humanReadableName = id.replace(/.*node_modules[\/\\]/, '').replace(/[\/\\]/g, '/');
      return getInjectorCode(humanReadableName, code);
    }

  };
}

const CACHED_FILE_ID_PREFIX = 'snowpack-pkg-cache:';
const PIKA_CDN_TRIM_LENGTH = PIKA_CDN.length;
/**
 * rollup-plugin-remote-cdn
 *
 * Load import URLs from a remote CDN, sitting behind a local cache. The local
 * cache acts as a go-between for the resolve & load step: when we get back a
 * successful CDN resolution, we save the file to the local cache and then tell
 * rollup that it's safe to load from the cache in the `load()` hook.
 */

function rollupPluginDependencyCache({
  installTypes,
  log
}) {
  const allTypesToInstall = new Set();
  return {
    name: 'snowpack:rollup-plugin-remote-cdn',

    async resolveId(source, importer) {
      let cacheKey;

      if (source.startsWith(PIKA_CDN)) {
        cacheKey = source;
      } else if (source.startsWith('/-/')) {
        cacheKey = PIKA_CDN + source;
      } else if (source.startsWith('/pin/')) {
        cacheKey = PIKA_CDN + source;
      } else {
        return null;
      } // If the source path is a CDN path including a hash, it's assumed the
      // file will never change and it is safe to pull from our local cache
      // without a network request.


      log(cacheKey);

      if (HAS_CDN_HASH_REGEX.test(cacheKey)) {
        const cachedResult = await cacache.get.info(RESOURCE_CACHE, cacheKey).catch(() =>
        /* ignore */
        null);

        if (cachedResult) {
          return CACHED_FILE_ID_PREFIX + cacheKey;
        }
      } // Otherwise, make the remote request and cache the file on success.


      const response = await fetchCDNResource(cacheKey);

      if (response.statusCode === 200) {
        const typesUrlPath = response.headers['x-typescript-types'];
        const pinnedUrlPath = response.headers['x-pinned-url'];
        const typesUrl = typesUrlPath && `${PIKA_CDN}${typesUrlPath}`;
        const pinnedUrl = pinnedUrlPath && `${PIKA_CDN}${pinnedUrlPath}`;
        await cacache.put(RESOURCE_CACHE, cacheKey, response.body, {
          metadata: {
            pinnedUrl,
            typesUrl
          }
        });
        return CACHED_FILE_ID_PREFIX + cacheKey;
      } // If lookup failed, skip this plugin and resolve the import locally instead.
      // TODO: Log that this has happened (if some sort of verbose mode is enabled).


      const packageName = cacheKey.substring(PIKA_CDN_TRIM_LENGTH).replace('/-/', '').replace('/pin/', '').split('@')[0];
      return this.resolve(packageName, importer, {
        skipSelf: true
      }).then(resolved => {
        let finalResult = resolved;

        if (!finalResult) {
          finalResult = {
            id: packageName
          };
        }

        return finalResult;
      });
    },

    async load(id) {
      var _cachedResult$metadat;

      if (!id.startsWith(CACHED_FILE_ID_PREFIX)) {
        return null;
      }

      const cacheKey = id.substring(CACHED_FILE_ID_PREFIX.length);
      log(cacheKey);
      const cachedResult = await cacache.get(RESOURCE_CACHE, cacheKey);
      const typesUrl = (_cachedResult$metadat = cachedResult.metadata) === null || _cachedResult$metadat === void 0 ? void 0 : _cachedResult$metadat.typesUrl;

      if (typesUrl && installTypes) {
        const typesTarballUrl = typesUrl.replace(/(mode=types.*?)\/.*/, '$1/all.tgz');
        allTypesToInstall.add(typesTarballUrl);
      }

      return cachedResult.data.toString('utf-8');
    },

    async writeBundle(options) {
      if (!installTypes) {
        return;
      }

      await mkdirp(path.join(options.dir, '.types'));
      const tempDir = await cacache.tmp.mkdir(RESOURCE_CACHE);

      for (const typesTarballUrl of allTypesToInstall) {
        let tarballContents;
        const cachedTarball = await cacache.get(RESOURCE_CACHE, typesTarballUrl).catch(() =>
        /* ignore */
        null);

        if (cachedTarball) {
          tarballContents = cachedTarball.data;
        } else {
          const tarballResponse = await fetchCDNResource(typesTarballUrl, 'buffer');

          if (tarballResponse.statusCode !== 200) {
            continue;
          }

          tarballContents = tarballResponse.body;
          await cacache.put(RESOURCE_CACHE, typesTarballUrl, tarballContents);
        }

        const typesUrlParts = url.parse(typesTarballUrl).pathname.split('/');
        const typesPackageName = url.parse(typesTarballUrl).pathname.startsWith('/-/@') ? typesUrlParts[2] + '/' + typesUrlParts[3].split('@')[0] : typesUrlParts[2].split('@')[0];
        const typesPackageTarLoc = path.join(tempDir, `${typesPackageName}.tgz`);

        if (typesPackageName.includes('/')) {
          await mkdirp(path.dirname(typesPackageTarLoc));
        }

        fs__default.writeFileSync(typesPackageTarLoc, tarballContents);
        const typesPackageLoc = path.join(options.dir, `.types/${typesPackageName}`);
        await mkdirp(typesPackageLoc);
        await tar.x({
          file: typesPackageTarLoc,
          cwd: typesPackageLoc
        });
      }
    }

  };
}

function rollupPluginDependencyStats(cb) {
  let outputDir;
  let existingFileCache = {};
  let statsSummary = {
    direct: {},
    common: {}
  };

  function buildExistingFileCache(bundle) {
    for (let fileName of Object.keys(bundle)) {
      const filePath = path.join(outputDir, fileName);

      if (fs__default.existsSync(filePath)) {
        const {
          size
        } = fs__default.statSync(filePath);
        existingFileCache[fileName] = size;
      }
    }
  }

  function compareDependencies(files, type) {
    for (let {
      fileName,
      contents
    } of files) {
      const size = contents.byteLength;
      statsSummary[type][fileName] = {
        size: size,
        gzip: zlib.gzipSync(contents).byteLength,
        brotli: zlib.brotliCompressSync ? zlib.brotliCompressSync(contents).byteLength : 0
      };

      if (existingFileCache[fileName]) {
        const delta = (size - existingFileCache[fileName]) / 1000;
        statsSummary[type][fileName].delta = delta;
      }
    }
  }

  return {
    name: 'snowpack:rollup-plugin-stats',

    generateBundle(options, bundle) {
      outputDir = options.dir;
      buildExistingFileCache(bundle);
    },

    writeBundle(_, bundle) {
      const directDependencies = [];
      const commonDependencies = [];

      for (const [fileName, assetOrChunk] of Object.entries(bundle)) {
        const raw = assetOrChunk.type === 'asset' ? assetOrChunk.source : assetOrChunk.code;
        const contents = Buffer.isBuffer(raw) ? raw : typeof raw === 'string' ? Buffer.from(raw, 'utf-8') : Buffer.from(raw);

        if (fileName.startsWith('common')) {
          commonDependencies.push({
            fileName,
            contents
          });
        } else {
          directDependencies.push({
            fileName,
            contents
          });
        }
      }

      compareDependencies(directDependencies, 'direct');
      compareDependencies(commonDependencies, 'common');
      cb(statsSummary);
    }

  };
}

function autoDetectExports(fileLoc) {
  try {
    return Object.keys(require(fileLoc)).filter(imp => imp !== 'default');
  } catch (err) {
    logger.error(`✘ Could not auto-detect exports for ${colors.bold(fileLoc)}
${err.message}`);
  }
}
/**
 * rollup-plugin-wrap-install-targets
 *
 * How it works:
 * 1. An array of "install targets" are passed in, describing all known imports + metadata.
 * 2. If isTreeshake: Known imports are marked for tree-shaking by appending 'snowpack-wrap:' to the input value.
 * 3. If autoDetectPackageExports match: Also mark for wrapping, and use automatic export detection.
 * 4. On load, we return a false virtual file for all "snowpack-wrap:" inputs.
 *    a. That virtual file contains only `export ... from 'ACTUAL_FILE_PATH';` exports
 *    b. Rollup uses those exports to drive its tree-shaking algorithm.
 *    c. Rollup uses those exports to inform its "namedExports" for Common.js entrypoints.
 */


function rollupPluginWrapInstallTargets(isTreeshake, autoDetectPackageExports, installTargets) {
  const installTargetSummaries = {};

  function isAutoDetect(normalizedFileLoc) {
    return autoDetectPackageExports.some(p => normalizedFileLoc.includes(`node_modules/${p}${p.endsWith('.js') ? '' : '/'}`));
  }

  return {
    name: 'snowpack:wrap-install-targets',

    // Mark some inputs for tree-shaking.
    buildStart(inputOptions) {
      const input = inputOptions.input;

      for (const [key, val] of Object.entries(input)) {
        const allInstallTargets = installTargets.filter(imp => getWebDependencyName(imp.specifier) === key);
        const installTargetSummary = allInstallTargets.reduce((summary, imp) => {
          summary.all = summary.all || imp.all;
          summary.default = summary.default || imp.default || imp.all;
          summary.namespace = summary.namespace || imp.namespace || imp.all;
          summary.named = [...(summary.named || []), ...imp.named];
          return summary;
        }, {});
        installTargetSummaries[val] = installTargetSummary;
        const normalizedFileLoc = val.split(path.win32.sep).join(path.posix.sep);

        if (isAutoDetect(normalizedFileLoc)) {
          input[key] = `snowpack-wrap:${val}`;
        }

        if (isTreeshake && !installTargetSummary.all) {
          input[key] = `snowpack-wrap:${val}`;
        }
      }
    },

    resolveId(source) {
      if (source.startsWith('snowpack-wrap:')) {
        return source;
      }

      return null;
    },

    load(id) {
      if (!id.startsWith('snowpack-wrap:')) {
        return null;
      }

      const fileLoc = id.substring('snowpack-wrap:'.length); // Reduce all install targets into a single "summarized" install target.

      const installTargetSummary = installTargetSummaries[fileLoc];
      let uniqueNamedImports = Array.from(new Set(installTargetSummary.named));
      const normalizedFileLoc = fileLoc.split(path.win32.sep).join(path.posix.sep);

      if ((!isTreeshake || installTargetSummary.namespace) && isAutoDetect(normalizedFileLoc)) {
        uniqueNamedImports = autoDetectExports(fileLoc) || uniqueNamedImports;
        installTargetSummary.default = true;
      }

      const result = `
        ${installTargetSummary.namespace ? `export * from '${normalizedFileLoc}';` : ''}
        ${installTargetSummary.default ? `import __pika_web_default_export_for_treeshaking__ from '${normalizedFileLoc}'; export default __pika_web_default_export_for_treeshaking__;` : ''}
        ${`export {${uniqueNamedImports.join(',')}} from '${normalizedFileLoc}';`}
      `;
      return result;
    }

  };
}

/*
(The MIT License)

Copyright (c) 2013 Roman Shtylman <shtylman@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*/

/*
THIS IS A MODIFIED VERSION OF https://github.com/calvinmetcalf/node-process-es6
ORIGIANL ADDED IN COMMIT 6304406e065f356aeaa623a878d02be419b316d8 (good to know for diffing)
*/
function generateProcessPolyfill(env) {
  return `/* SNOWPACK PROCESS POLYFILL (based on https://github.com/calvinmetcalf/node-process-es6) */
function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
var cachedSetTimeout = defaultSetTimout;
var cachedClearTimeout = defaultClearTimeout;
var globalContext;
if (typeof window !== 'undefined') {
    globalContext = window;
} else if (typeof self !== 'undefined') {
    globalContext = self;
} else {
    globalContext = {};
}
if (typeof globalContext.setTimeout === 'function') {
    cachedSetTimeout = setTimeout;
}
if (typeof globalContext.clearTimeout === 'function') {
    cachedClearTimeout = clearTimeout;
}

function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }


}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }



}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}
function nextTick(fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
}
// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
var title = 'browser';
var platform = 'browser';
var browser = true;
var env = {};
var argv = [];
var version = ''; // empty string to avoid regexp issues
var versions = {};
var release = {};
var config = {};

function noop() {}

var on = noop;
var addListener = noop;
var once = noop;
var off = noop;
var removeListener = noop;
var removeAllListeners = noop;
var emit = noop;

function binding(name) {
    throw new Error('process.binding is not supported');
}

function cwd () { return '/' }
function chdir (dir) {
    throw new Error('process.chdir is not supported');
}function umask() { return 0; }

// from https://github.com/kumavis/browser-process-hrtime/blob/master/index.js
var performance = globalContext.performance || {};
var performanceNow =
  performance.now        ||
  performance.mozNow     ||
  performance.msNow      ||
  performance.oNow       ||
  performance.webkitNow  ||
  function(){ return (new Date()).getTime() };

// generate timestamp or delta
// see http://nodejs.org/api/process.html#process_process_hrtime
function hrtime(previousTimestamp){
  var clocktime = performanceNow.call(performance)*1e-3;
  var seconds = Math.floor(clocktime);
  var nanoseconds = Math.floor((clocktime%1)*1e9);
  if (previousTimestamp) {
    seconds = seconds - previousTimestamp[0];
    nanoseconds = nanoseconds - previousTimestamp[1];
    if (nanoseconds<0) {
      seconds--;
      nanoseconds += 1e9;
    }
  }
  return [seconds,nanoseconds]
}

var startTime = new Date();
function uptime() {
  var currentTime = new Date();
  var dif = currentTime - startTime;
  return dif / 1000;
}

export default {
  nextTick: nextTick,
  title: title,
  browser: browser,
  env: ${JSON.stringify(env)},
  argv: argv,
  version: version,
  versions: versions,
  on: on,
  addListener: addListener,
  once: once,
  off: off,
  removeListener: removeListener,
  removeAllListeners: removeAllListeners,
  emit: emit,
  binding: binding,
  cwd: cwd,
  chdir: chdir,
  umask: umask,
  hrtime: hrtime,
  platform: platform,
  release: release,
  config: config,
  uptime: uptime
};

export { addListener, argv, binding, browser, chdir, config, cwd, emit, env, hrtime, nextTick, off, on, once, platform, release, removeAllListeners, removeListener, title, umask, uptime, version, versions };
`;
}

const PROCESS_MODULE_NAME = 'process';
function rollupPluginNodeProcessPolyfill(env = {}) {
  const injectPlugin = inject({
    process: PROCESS_MODULE_NAME
  });
  return _objectSpread2(_objectSpread2({}, injectPlugin), {}, {
    name: 'snowpack:rollup-plugin-node-process-polyfill',

    resolveId(source) {
      if (source === PROCESS_MODULE_NAME) {
        return PROCESS_MODULE_NAME;
      }

      return null;
    },

    load(id) {
      if (id === PROCESS_MODULE_NAME) {
        return {
          code: generateProcessPolyfill(env),
          moduleSideEffects: false
        };
      }

      return null;
    }

  });
}

/**
 * rollup-plugin-strip-source-mapping
 *
 * Remove any lingering source map comments
 */
function rollupPluginStripSourceMapping() {
  return {
    name: 'snowpack:rollup-plugin-strip-source-mapping',
    transform: code => ({
      code: code.replace(/\/\/+#\s*sourceMappingURL=.+$/gm, ''),
      map: null
    })
  };
}

// (?!.*(:\/\/)) - Ignore if previous match was a protocol (ex: http://)

const BARE_SPECIFIER_REGEX = /^[@\w](?!.*(:\/\/))/;
const ESM_IMPORT_REGEX = /import(?:["'\s]*([\w*${}\n\r\t, ]+)\s*from\s*)?\s*["'](.*?)["']/gm;
const ESM_DYNAMIC_IMPORT_REGEX = /(?<!\.)\bimport\((?:['"].+['"]|`[^$]+`)\)/gm;
const HAS_NAMED_IMPORTS_REGEX = /^[\t-\r ,0-9A-Z_a-z\xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\{([\s\S]*)\}/;
const STRIP_AS = /\s+as\s+.*/; // for `import { foo as bar }`, strips “as bar”

const DEFAULT_IMPORT_REGEX = /import[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+([0-9A-Z_a-z])+(,[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]\{[\t-\r 0-9A-Z_a-z\xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]*\})?[\t-\r \xA0\u1680\u2000-\u200A\u2028\u2029\u202F\u205F\u3000\uFEFF]+from/;

function createInstallTarget(specifier, all = true) {
  return {
    specifier,
    all,
    default: false,
    namespace: false,
    named: []
  };
}

function matchDynamicImportValue(importStatement) {
  const matched = stripComments(importStatement).match(/^\s*('([^']+)'|"([^"]+)")\s*$/m);
  return (matched === null || matched === void 0 ? void 0 : matched[2]) || (matched === null || matched === void 0 ? void 0 : matched[3]) || null;
}

function getWebModuleSpecifierFromCode(code, imp) {
  // import.meta: we can ignore
  if (imp.d === -2) {
    return null;
  } // Static imports: easy to parse


  if (imp.d === -1) {
    return code.substring(imp.s, imp.e);
  } // Dynamic imports: a bit trickier to parse. Today, we only support string literals.


  const importStatement = code.substring(imp.s, imp.e);
  return matchDynamicImportValue(importStatement);
}
/**
 * parses an import specifier, looking for a web modules to install. If a web module is not detected,
 * null is returned.
 */


function parseWebModuleSpecifier(specifier) {
  if (!specifier) {
    return null;
  } // If specifier is a "bare module specifier" (ie: package name) just return it directly


  if (BARE_SPECIFIER_REGEX.test(specifier)) {
    return specifier;
  }

  return null;
}

function parseImportStatement(code, imp) {
  const webModuleSpecifier = parseWebModuleSpecifier(getWebModuleSpecifierFromCode(code, imp));

  if (!webModuleSpecifier) {
    return null;
  }

  const importStatement = stripComments(code.substring(imp.ss, imp.se));

  if (/^import\s+type/.test(importStatement)) {
    return null;
  }

  const isDynamicImport = imp.d > -1;
  const hasDefaultImport = !isDynamicImport && DEFAULT_IMPORT_REGEX.test(importStatement);
  const hasNamespaceImport = !isDynamicImport && importStatement.includes('*');
  const namedImports = (importStatement.match(HAS_NAMED_IMPORTS_REGEX) || [, ''])[1].split(',') // split `import { a, b, c }` by comma
  .map(name => name.replace(STRIP_AS, '').trim()) // remove “ as …” and trim
  .filter(isTruthy);
  return {
    specifier: webModuleSpecifier,
    all: isDynamicImport || !hasDefaultImport && !hasNamespaceImport && namedImports.length === 0,
    default: hasDefaultImport,
    namespace: hasNamespaceImport,
    named: namedImports
  };
}

function cleanCodeForParsing(code) {
  code = stripComments(code);
  const allMatches = [];
  let match;
  const importRegex = new RegExp(ESM_IMPORT_REGEX);

  while (match = importRegex.exec(code)) {
    allMatches.push(match);
  }

  const dynamicImportRegex = new RegExp(ESM_DYNAMIC_IMPORT_REGEX);

  while (match = dynamicImportRegex.exec(code)) {
    allMatches.push(match);
  }

  return allMatches.map(([full]) => full).join('\n');
}

function parseJsForInstallTargets(contents) {
  let imports; // Attempt #1: Parse the file as JavaScript. JSX and some decorator
  // syntax will break this.

  try {
    [imports] = esModuleLexer.parse(contents) || [];
  } catch (err) {
    // Attempt #2: Parse only the import statements themselves.
    // This lets us guarentee we aren't sending any broken syntax to our parser,
    // but at the expense of possible false +/- caused by our regex extractor.
    contents = cleanCodeForParsing(contents);
    [imports] = esModuleLexer.parse(contents) || [];
  }

  return imports.map(imp => parseImportStatement(contents, imp)).filter(isTruthy) // Babel macros are not install targets!
  .filter(target => !/[./]macro(\.js)?$/.test(target.specifier));
}

function parseCssForInstallTargets(code) {
  const installTargets = [];
  let match;
  const importRegex = new RegExp(CSS_REGEX);

  while (match = importRegex.exec(code)) {
    const [, spec] = match;
    const webModuleSpecifier = parseWebModuleSpecifier(spec);

    if (webModuleSpecifier) {
      installTargets.push(createInstallTarget(webModuleSpecifier));
    }
  }

  return installTargets;
}

function parseFileForInstallTargets({
  locOnDisk,
  baseExt,
  contents
}) {
  const relativeLoc = path.relative(process.cwd(), locOnDisk);

  try {
    switch (baseExt) {
      case '.css':
      case '.less':
      case '.sass':
      case '.scss':
        {
          logger.debug(`Scanning ${relativeLoc} for imports as CSS`);
          return parseCssForInstallTargets(contents);
        }

      case '.html':
      case '.svelte':
      case '.vue':
        {
          logger.debug(`Scanning ${relativeLoc} for imports as HTML`);
          return parseJsForInstallTargets(extractJSFromHTML({
            contents,
            baseExt
          }));
        }

      case '.js':
      case '.jsx':
      case '.mjs':
      case '.ts':
      case '.tsx':
        {
          logger.debug(`Scanning ${relativeLoc} for imports as JS`);
          return parseJsForInstallTargets(contents);
        }

      default:
        {
          logger.debug(`Skip scanning ${relativeLoc} for imports (unknown file extension ${baseExt})`);
          return [];
        }
    }
  } catch (err) {
    // Another error! No hope left, just abort.
    logger.error(`! ${locOnDisk}`);
    throw err;
  }
}
/** Extract only JS within <script type="module"> tags (works for .svelte and .vue files, too) */


function extractJSFromHTML({
  contents,
  baseExt
}) {
  // TODO: Replace with matchAll once Node v10 is out of TLS.
  // const allMatches = [...result.matchAll(new RegExp(HTML_JS_REGEX))];
  const allMatches = [];
  let match;
  let regex = new RegExp(HTML_JS_REGEX);

  if (baseExt === '.svelte' || baseExt === '.vue') {
    regex = new RegExp(SVELTE_VUE_REGEX); // scan <script> tags, not <script type="module">
  }

  while (match = regex.exec(contents)) {
    allMatches.push(match);
  }

  return allMatches.map(match => match[2]) // match[2] is the code inside the <script></script> element
  .filter(s => s.trim()).join('\n');
}

function scanDepList(depList, cwd) {
  return depList.map(whitelistItem => {
    if (!glob.hasMagic(whitelistItem)) {
      return [createInstallTarget(whitelistItem, true)];
    } else {
      const nodeModulesLoc = path.join(cwd, 'node_modules');
      return scanDepList(glob.sync(whitelistItem, {
        cwd: nodeModulesLoc,
        nodir: true
      }), cwd);
    }
  }).reduce((flat, item) => flat.concat(item), []);
}
async function scanImports(cwd, config) {
  await esModuleLexer.init;
  const includeFileSets = await Promise.all(Object.keys(config.mount).map(fromDisk => {
    const dirDisk = path.resolve(cwd, fromDisk);
    return glob.sync(`**/*`, {
      ignore: config.exclude.concat(['**/web_modules/**/*']),
      cwd: dirDisk,
      absolute: true,
      nodir: true
    });
  }));
  const includeFiles = Array.from(new Set([].concat.apply([], includeFileSets)));

  if (includeFiles.length === 0) {
    return [];
  } // Scan every matched JS file for web dependency imports


  const loadedFiles = await Promise.all(includeFiles.map(async filePath => {
    const {
      baseExt,
      expandedExt
    } = getExt(filePath);
    return {
      baseExt,
      expandedExt,
      locOnDisk: filePath,
      contents: await readFile(filePath)
    };
  }));
  return scanImportsFromFiles(loadedFiles.filter(isTruthy), config);
}
async function scanImportsFromFiles(loadedFiles, config) {
  return loadedFiles.filter(sourceFile => !Buffer.isBuffer(sourceFile.contents)) // filter out binary files from import scanning
  .map(sourceFile => parseFileForInstallTargets(sourceFile)).reduce((flat, item) => flat.concat(item), []).filter(target => {
    const aliasEntry = findMatchingAliasEntry(config, target.specifier);
    return !aliasEntry || aliasEntry.type === 'package';
  }).sort((impA, impB) => impA.specifier.localeCompare(impB.specifier));
}

/** The minimum width, in characters, of each size column */

const SIZE_COLUMN_WIDTH = 11;
/** Generic Object.entries() alphabetical sort by keys. */

function entriesSort([filenameA], [filenameB]) {
  return filenameA.localeCompare(filenameB);
}
/** Pretty-prints number of bytes as "XXX KB" */


function formatSize(size) {
  let kb = Math.round(size / 1000 * 100) / 100;

  if (kb >= 1000) {
    kb = Math.floor(kb);
  }

  let color;

  if (kb < 15) {
    color = 'green';
  } else if (kb < 30) {
    color = 'yellow';
  } else {
    color = 'red';
  }

  return colors[color](`${kb} KB`.padEnd(SIZE_COLUMN_WIDTH));
}

function formatDelta(delta) {
  const kb = Math.round(delta * 100) / 100;
  const color = delta > 0 ? 'red' : 'green';
  return colors[color](`Δ ${delta > 0 ? '+' : ''}${kb} KB`);
}

function formatFileInfo(filename, stats, padEnd, isLastFile) {
  const lineGlyph = colors.dim(isLastFile ? '└─' : '├─');
  const lineName = filename.padEnd(padEnd);
  const fileStat = formatSize(stats.size);
  const gzipStat = formatSize(stats.gzip);
  const brotliStat = formatSize(stats.brotli);
  const lineStat = fileStat + gzipStat + brotliStat;
  let lineDelta = '';

  if (stats.delta) {
    lineDelta = colors.dim('[') + formatDelta(stats.delta) + colors.dim(']');
  } // Trim trailing whitespace (can mess with formatting), but keep indentation.


  return `    ` + `${lineGlyph} ${lineName} ${lineStat} ${lineDelta}`.trim();
}

function formatFiles(files, padEnd) {
  const strippedFiles = files.map(([filename, stats]) => [filename.replace(/^common\//, ''), stats]);
  return strippedFiles.map(([filename, stats], index) => formatFileInfo(filename, stats, padEnd, index >= files.length - 1)).join('\n');
}

function printStats(dependencyStats) {
  let output = '';
  const {
    direct,
    common
  } = dependencyStats;
  const allDirect = Object.entries(direct).sort(entriesSort);
  const allCommon = Object.entries(common).sort(entriesSort);
  const maxFileNameLength = [...allCommon, ...allDirect].reduce((max, [filename]) => Math.max(filename.length, max), 'web_modules/'.length) + 1;
  output += `  ⦿ ${colors.bold('web_modules/'.padEnd(maxFileNameLength + 4))}` + colors.bold(colors.underline('size'.padEnd(SIZE_COLUMN_WIDTH - 2))) + '  ' + colors.bold(colors.underline('gzip'.padEnd(SIZE_COLUMN_WIDTH - 2))) + '  ' + colors.bold(colors.underline('brotli'.padEnd(SIZE_COLUMN_WIDTH - 2))) + `\n`;
  output += `${formatFiles(allDirect, maxFileNameLength)}\n`;

  if (Object.values(common).length > 0) {
    output += `  ⦿ ${colors.bold('web_modules/common/ (Shared)')}\n`;
    output += `${formatFiles(allCommon, maxFileNameLength)}\n`;
  }

  return `\n${output}\n`;
}

// CJS packages should really only be imported via the default export:
//   import React from 'react';
// But, some large projects use named exports in their documentation:
//   import {useState} from 'react';
//
// We use "/index.js here to match the official package, but not any ESM aliase packages
// that the user may have installed instead (ex: react-esm).

const CJS_PACKAGES_TO_AUTO_DETECT = ['react/index.js', 'react-dom/index.js', 'react-dom/server.js', 'react-is/index.js', 'prop-types/index.js', 'scheduler/index.js', 'react-table'];
const cwd = process.cwd();
let installResults = [];
let dependencyStats = null;

function isImportOfPackage(importUrl, packageName) {
  return packageName === importUrl || importUrl.startsWith(packageName + '/');
}
/**
 * Resolve a "webDependencies" input value to the correct absolute file location.
 * Supports both npm package names, and file paths relative to the node_modules directory.
 * Follows logic similar to Node's resolution logic, but using a package.json's ESM "module"
 * field instead of the CJS "main" field.
 */


function resolveWebDependency(dep) {
  // if dep points directly to a file within a package, return that reference.
  // No other lookup required.
  if (path.extname(dep) && !validatePackageName(dep).validForNewPackages) {
    const isJSFile = ['.js', '.mjs', '.cjs'].includes(path.extname(dep));
    return {
      type: isJSFile ? 'JS' : 'ASSET',
      // For details on why we need to call fs.realpathSync.native here and other places, see
      // https://github.com/pikapkg/snowpack/pull/999.
      loc: fs__default.realpathSync.native(require.resolve(dep, {
        paths: [cwd]
      }))
    };
  } // If dep is a path within a package (but without an extension), we first need
  // to check for an export map in the package.json. If one exists, resolve to it.


  const [packageName, packageEntrypoint] = parsePackageImportSpecifier(dep);

  if (packageEntrypoint) {
    const [packageManifestLoc, packageManifest] = resolveDependencyManifest(packageName, cwd);

    if (packageManifestLoc && packageManifest && packageManifest.exports) {
      const exportMapEntry = packageManifest.exports['./' + packageEntrypoint];
      const exportMapValue = (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.browser) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.import) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.default) || (exportMapEntry === null || exportMapEntry === void 0 ? void 0 : exportMapEntry.require) || exportMapEntry;

      if (typeof exportMapValue !== 'string') {
        logger.error(`Package "${packageName}" exists but package.json "exports" does not include entry for "./${packageEntrypoint}".`);
        process.exit(1);
      }

      return {
        type: 'JS',
        loc: path.join(packageManifestLoc, '..', exportMapValue)
      };
    }
  } // Otherwise, resolve directly to the dep specifier. Note that this supports both
  // "package-name" & "package-name/some/path" where "package-name/some/path/package.json"
  // exists at that lower path, that must be used to resolve. In that case, export
  // maps should not be supported.


  const [depManifestLoc, depManifest] = resolveDependencyManifest(dep, cwd);

  if (!depManifest) {
    try {
      const maybeLoc = fs__default.realpathSync.native(require.resolve(dep, {
        paths: [cwd]
      }));
      return {
        type: 'JS',
        loc: maybeLoc
      };
    } catch (err) {// Oh well, was worth a try
    }
  }

  if (!depManifestLoc || !depManifest) {
    throw new Error(`Package "${dep}" not found. Have you installed it? ${depManifestLoc ? depManifestLoc : ''}`);
  }

  if (depManifest.name && (depManifest.name.startsWith('@reactesm') || depManifest.name.startsWith('@pika/react'))) {
    logger.error(`React workaround packages no longer needed! Revert back to the official React & React-DOM packages.`);
    process.exit(1);
  }

  let foundEntrypoint = depManifest['browser:module'] || depManifest.module || depManifest['main:esnext'] || depManifest.browser; // Some packages define "browser" as an object. We'll do our best to find the
  // right entrypoint in an entrypoint object, or fail otherwise.
  // See: https://github.com/defunctzombie/package-browser-field-spec

  if (typeof foundEntrypoint === 'object') {
    foundEntrypoint = foundEntrypoint[dep] || foundEntrypoint['./index.js'] || foundEntrypoint['./index'] || foundEntrypoint['./'] || foundEntrypoint['.'];
  } // If browser object is set but no relevant entrypoint is found, fall back to "main".


  if (!foundEntrypoint) {
    foundEntrypoint = depManifest.main;
  } // Sometimes packages don't give an entrypoint, assuming you'll fall back to "index.js".


  const isImplicitEntrypoint = !foundEntrypoint;

  if (isImplicitEntrypoint) {
    foundEntrypoint = 'index.js';
  }

  if (typeof foundEntrypoint !== 'string') {
    throw new Error(`"${dep}" has unexpected entrypoint: ${JSON.stringify(foundEntrypoint)}.`);
  }

  try {
    return {
      type: 'JS',
      loc: fs__default.realpathSync.native(require.resolve(path.join(depManifestLoc || '', '..', foundEntrypoint)))
    };
  } catch (err) {
    // Type only packages! Some packages are purely for TypeScript (ex: csstypes).
    // If no JS entrypoint was given or found, but a TS "types"/"typings" entrypoint
    // was given, assume a TS-types only package and ignore.
    if (isImplicitEntrypoint && (depManifest.types || depManifest.typings)) {
      return {
        type: 'IGNORE',
        loc: ''
      };
    } // Otherwise, file truly doesn't exist.


    throw err;
  }
}

function generateEnvObject(userEnv) {
  return _objectSpread2({
    NODE_ENV: process.env.NODE_ENV || 'production'
  }, Object.keys(userEnv).reduce((acc, key) => {
    const value = userEnv[key];
    acc[key] = value === true ? process.env[key] : value;
    return acc;
  }, {}));
}

function generateEnvReplacements(env) {
  return Object.keys(env).reduce((acc, key) => {
    acc[`process.env.${key}`] = JSON.stringify(env[key]);
    return acc;
  }, {});
}

const FAILED_INSTALL_MESSAGE = 'Install failed.';
const EMPTY_INSTALL_RETURN = {
  success: false,
  importMap: null
};
async function install(installTargets, {
  lockfile,
  config
}) {
  const {
    webDependencies,
    alias: installAlias,
    installOptions: {
      installTypes,
      dest: destLoc,
      externalPackage: externalPackages,
      sourceMap,
      env: userEnv,
      rollup: userDefinedRollup,
      treeshake: isTreeshake,
      polyfillNode
    }
  } = config;
  const env = generateEnvObject(userEnv);
  const nodeModulesInstalled = findUp.sync('node_modules', {
    cwd,
    type: 'directory'
  });

  if (!webDependencies && !process.versions.pnp && !nodeModulesInstalled) {
    logger.error('No "node_modules" directory exists. Did you run "npm install" first?');
    return EMPTY_INSTALL_RETURN;
  }

  const allInstallSpecifiers = new Set(installTargets.filter(dep => !externalPackages.some(packageName => isImportOfPackage(dep.specifier, packageName))).map(dep => dep.specifier).map(specifier => {
    const aliasEntry = findMatchingAliasEntry(config, specifier);
    return aliasEntry && aliasEntry.type === 'package' ? aliasEntry.to : specifier;
  }).sort());
  const installEntrypoints = {};
  const assetEntrypoints = {};
  const importMap = {
    imports: {}
  };
  const autoDetectNamedExports = [...CJS_PACKAGES_TO_AUTO_DETECT, ...config.installOptions.namedExports];

  for (const installSpecifier of allInstallSpecifiers) {
    const targetName = getWebDependencyName(installSpecifier);
    const proxiedName = sanitizePackageName(targetName); // sometimes we need to sanitize webModule names, as in the case of tippy.js -> tippyjs

    if (lockfile && lockfile.imports[installSpecifier]) {
      installEntrypoints[targetName] = lockfile.imports[installSpecifier];
      importMap.imports[installSpecifier] = `./${proxiedName}.js`;
      installResults.push([targetName, 'SUCCESS']);
      continue;
    }

    try {
      const {
        type: targetType,
        loc: targetLoc
      } = resolveWebDependency(installSpecifier);

      if (targetType === 'JS') {
        installEntrypoints[targetName] = targetLoc;
        importMap.imports[installSpecifier] = `./${proxiedName}.js`;
        Object.entries(installAlias).filter(([, value]) => value === installSpecifier).forEach(([key]) => {
          importMap.imports[key] = `./${targetName}.js`;
        });
        installResults.push([installSpecifier, 'SUCCESS']);
      } else if (targetType === 'ASSET') {
        assetEntrypoints[targetName] = targetLoc;
        importMap.imports[installSpecifier] = `./${proxiedName}`;
        installResults.push([installSpecifier, 'ASSET']);
      }
    } catch (err) {
      installResults.push([installSpecifier, 'FAIL']);

      logger.error(err.message || err);
      throw new Error(FAILED_INSTALL_MESSAGE);
    }
  }

  if (Object.keys(installEntrypoints).length === 0 && Object.keys(assetEntrypoints).length === 0) {
    logger.error(`No ESM dependencies found!
${colors.dim(`  At least one dependency must have an ESM "module" entrypoint. You can find modern, web-ready packages at ${colors.underline('https://www.pika.dev')}`)}`);
    return EMPTY_INSTALL_RETURN;
  }

  await esModuleLexer.init;
  let isCircularImportFound = false;
  let isFatalWarningFound = false;
  const inputOptions = {
    input: installEntrypoints,
    external: id => externalPackages.some(packageName => isImportOfPackage(id, packageName)),
    treeshake: {
      moduleSideEffects: 'no-external'
    },
    plugins: [!!webDependencies && rollupPluginDependencyCache({
      installTypes,
      log: url => {
        logger.debug(`installing ${colors.dim(url)}…`);
      }
    }), rollupPluginAlias({
      entries: Object.entries(installAlias).filter(([, val]) => isPackageAliasEntry(val)).map(([key, val]) => ({
        find: key,
        replacement: val
      }))
    }), rollupPluginCatchFetch(), rollupPluginNodeResolve({
      mainFields: ['browser:module', 'module', 'browser', 'main'].filter(isTruthy),
      extensions: ['.mjs', '.cjs', '.js', '.json'],
      // whether to prefer built-in modules (e.g. `fs`, `path`) or local ones with the same names
      preferBuiltins: true,
      dedupe: userDefinedRollup.dedupe
    }), rollupPluginJson({
      preferConst: true,
      indent: '  ',
      compact: false,
      namedExports: true
    }), rollupPluginCss(), rollupPluginReplace(generateEnvReplacements(env)), rollupPluginCommonjs({
      extensions: ['.js', '.cjs'],
      externalEsm: process.env.EXTERNAL_ESM_PACKAGES || [],
      requireReturnsDefault: 'auto'
    }), rollupPluginWrapInstallTargets(!!isTreeshake, autoDetectNamedExports, installTargets), rollupPluginDependencyStats(info => dependencyStats = info), rollupPluginNodeProcessPolyfill(env), polyfillNode && rollupPluginNodePolyfills(), ...userDefinedRollup.plugins, rollupPluginCatchUnresolved(), rollupPluginStripSourceMapping()].filter(Boolean),

    onwarn(warning, warn) {
      // Warn about the first circular dependency, but then ignore the rest.
      if (warning.code === 'CIRCULAR_DEPENDENCY') {
        if (!isCircularImportFound) {
          isCircularImportFound = true;
          logger.warn(`Warning: 1+ circular dependencies found via "${warning.importer}".`);
        }

        return;
      } // Log "unresolved" import warnings as an error, causing Snowpack to fail at the end.


      if (warning.code === 'PLUGIN_WARNING' && warning.plugin === 'snowpack:rollup-plugin-catch-unresolved') {
        isFatalWarningFound = true; // Display posix-style on all environments, mainly to help with CI :)

        if (warning.id) {
          const fileName = path.relative(cwd, warning.id).replace(/\\/g, '/');
          logger.error(`${fileName}\n   ${warning.message}`);
        } else {
          logger.error(`${warning.message}. See https://www.snowpack.dev/#troubleshooting`);
        }

        return;
      }

      warn(warning);
    }

  };
  const outputOptions = {
    dir: destLoc,
    format: 'esm',
    sourcemap: sourceMap,
    exports: 'named',
    entryFileNames: chunk => {
      const targetName = getWebDependencyName(chunk.name);
      const proxiedName = sanitizePackageName(targetName);
      return `${proxiedName}.js`;
    },
    chunkFileNames: 'common/[name]-[hash].js'
  };

  if (Object.keys(installEntrypoints).length > 0) {
    try {
      logger.debug(`running installer with options: ${util.format(inputOptions)}`);
      const packageBundle = await rollup.rollup(inputOptions);
      logger.debug(`installing npm packages:\n    ${Object.keys(installEntrypoints).join('\n    ')}`);

      if (isFatalWarningFound) {
        throw new Error(FAILED_INSTALL_MESSAGE);
      }

      logger.debug(`writing install results to disk`);
      await packageBundle.write(outputOptions);
    } catch (_err) {
      var _err$loc;

      const err = _err;
      const errFilePath = ((_err$loc = err.loc) === null || _err$loc === void 0 ? void 0 : _err$loc.file) || err.id;

      if (!errFilePath) {
        throw err;
      } // NOTE: Rollup will fail instantly on most errors. Therefore, we can
      // only report one error at a time. `err.watchFiles` also exists, but
      // for now `err.loc.file` and `err.id` have all the info that we need.


      const failedExtension = path.extname(errFilePath);
      const suggestion = MISSING_PLUGIN_SUGGESTIONS[failedExtension] || err.message; // Display posix-style on all environments, mainly to help with CI :)

      const fileName = path.relative(cwd, errFilePath).replace(/\\/g, '/');
      logger.error(`Failed to load ${colors.bold(fileName)}\n  ${suggestion}`);
      throw new Error(FAILED_INSTALL_MESSAGE);
    }
  }

  mkdirp.sync(destLoc);
  await writeLockfile(path.join(destLoc, 'import-map.json'), importMap);

  for (const [assetName, assetLoc] of Object.entries(assetEntrypoints)) {
    const assetDest = `${destLoc}/${sanitizePackageName(assetName)}`;
    mkdirp.sync(path.dirname(assetDest));
    fs__default.copyFileSync(assetLoc, assetDest);
  }

  return {
    success: true,
    importMap
  };
}
async function getInstallTargets(config, scannedFiles) {
  const {
    knownEntrypoints,
    webDependencies
  } = config;
  const installTargets = [];

  if (knownEntrypoints) {
    installTargets.push(...scanDepList(knownEntrypoints, cwd));
  }

  if (webDependencies) {
    installTargets.push(...scanDepList(Object.keys(webDependencies), cwd));
  } // TODO: remove this if block; move logic inside scanImports


  if (scannedFiles) {
    installTargets.push(...(await scanImportsFromFiles(scannedFiles, config)));
  } else {
    installTargets.push(...(await scanImports(cwd, config)));
  }

  return installTargets;
}
async function command(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  logger.debug('Starting install');
  const installTargets = await getInstallTargets(config);
  logger.debug('Received install targets');

  if (installTargets.length === 0) {
    logger.error('Nothing to install.');
    return;
  }

  logger.debug('Running install command');
  const finalResult = await run(_objectSpread2(_objectSpread2({}, commandOptions), {}, {
    installTargets
  }));
  logger.debug('Install command successfully ran');

  if (finalResult.newLockfile) {
    await writeLockfile(path.join(cwd, 'snowpack.lock.json'), finalResult.newLockfile);
    logger.debug('Successfully wrote lockfile');
  }

  if (finalResult.stats) {
    logger.info(printStats(finalResult.stats));
  }

  if (!finalResult.success || finalResult.hasError) {
    process.exit(1);
  }
}
async function run({
  config,
  lockfile,
  installTargets
}) {
  const {
    installOptions: {
      dest
    },
    webDependencies
  } = config; // start

  const installStart = perf_hooks.performance.now();
  logger.info(colors.yellow('! installing dependencies…'));
  installResults = [];
  dependencyStats = null;

  if (installTargets.length === 0) {
    return {
      success: true,
      hasError: false,
      importMap: {
        imports: {}
      },
      newLockfile: null,
      stats: null
    };
  }

  let newLockfile = null;

  if (webDependencies && Object.keys(webDependencies).length > 0) {
    newLockfile = await resolveTargetsFromRemoteCDN(lockfile, config).catch(err => {
      logger.error('\n' + err.message || err);
      process.exit(1);
    });
  }

  rimraf.sync(dest);
  const finalResult = await install(installTargets, {
    lockfile: newLockfile,
    config
  }).catch(err => {
    if (err.loc) {
      logger.error(colors.red(colors.bold(`✘ ${err.loc.file}`)));
    }

    if (err.url) {
      logger.error(colors.dim(`👉 ${err.url}`));
    }

    logger.error(err.message || err);
    process.exit(1);
  }); // finish

  const installEnd = perf_hooks.performance.now();
  const depList = finalResult.importMap && Object.keys(finalResult.importMap.imports) || [];
  logger.info(`${depList.length ? colors.green(`✔`) + ' install complete' : 'install skipped (nothing to install)'} ${colors.dim(`[${((installEnd - installStart) / 1000).toFixed(2)}s]`)}`);
  return {
    success: true,
    hasError: false,
    importMap: finalResult.importMap,
    newLockfile,
    stats: dependencyStats
  };
}

async function addCommand(addValue, commandOptions) {
  const {
    cwd,
    config,
    pkgManifest
  } = commandOptions;
  let [pkgName, pkgSemver] = addValue.split('@');

  if (!pkgSemver) {
    const body = await got(`http://registry.npmjs.org/${pkgName}/latest`).json();
    pkgSemver = `^${body.version}`;
  }

  pkgManifest.webDependencies = pkgManifest.webDependencies || {};
  pkgManifest.webDependencies[pkgName] = pkgSemver;
  config.webDependencies = config.webDependencies || {};
  config.webDependencies[pkgName] = pkgSemver;
  await fs.promises.writeFile(path.join(cwd, 'package.json'), JSON.stringify(pkgManifest, null, 2));
  await command(commandOptions);
}
async function rmCommand(addValue, commandOptions) {
  const {
    cwd,
    config,
    pkgManifest
  } = commandOptions;
  let [pkgName] = addValue.split('@');
  pkgManifest.webDependencies = pkgManifest.webDependencies || {};
  delete pkgManifest.webDependencies[pkgName];
  config.webDependencies = config.webDependencies || {};
  delete config.webDependencies[pkgName];
  await fs.promises.writeFile(path.join(cwd, 'package.json'), JSON.stringify(pkgManifest, null, 2));
  await command(commandOptions);
}

function getMetaUrlPath(urlPath, config) {
  let {
    metaDir
  } = config.buildOptions || {};
  return path.posix.normalize(path.posix.join('/', metaDir, urlPath));
}
function wrapImportMeta({
  code,
  hmr,
  env,
  config
}) {
  if (!code.includes('import.meta')) {
    return code;
  }

  return (hmr ? `import * as  __SNOWPACK_HMR__ from '${getMetaUrlPath('hmr.js', config)}';\nimport.meta.hot = __SNOWPACK_HMR__.createHotContext(import.meta.url);\n` : ``) + (env ? `import __SNOWPACK_ENV__ from '${getMetaUrlPath('env.js', config)}';\nimport.meta.env = __SNOWPACK_ENV__;\n` : ``) + '\n' + code;
}
function wrapHtmlResponse({
  code,
  hmr,
  isDev,
  config,
  mode
}) {
  // replace %PUBLIC_URL% (along with surrounding slashes, if any)
  code = code.replace(/\/?%PUBLIC_URL%\/?/g, isDev ? '/' : config.buildOptions.baseUrl); // replace %MODE%

  code = code.replace(/%MODE%/g, mode);
  const snowpackPublicEnv = getSnowpackPublicEnvVariables();
  code = code.replace(/%SNOWPACK_PUBLIC_.+?%/gi, match => {
    const envVariableName = match.slice(1, -1);

    if (envVariableName in snowpackPublicEnv) {
      return snowpackPublicEnv[envVariableName] || '';
    }

    logger.warn(`Environment variable "${envVariableName}" is not set`);
    return match;
  });

  if (hmr) {
    const hmrScript = `<script type="module" src="${getMetaUrlPath('hmr.js', config)}"></script>`;
    code = appendHTMLToBody(code, hmrScript);
  }

  return code;
}

function generateJsonImportProxy({
  code,
  hmr,
  config
}) {
  const jsonImportProxyCode = `let json = ${JSON.stringify(JSON.parse(code))};
export default json;`;
  return wrapImportMeta({
    code: jsonImportProxyCode,
    hmr,
    env: false,
    config
  });
}

function generateCssImportProxy({
  code,
  hmr,
  config
}) {
  const cssImportProxyCode = `${hmr ? `
import.meta.hot.accept();
import.meta.hot.dispose(() => {
document.head.removeChild(styleEl);
});\n` : ''}
const code = ${JSON.stringify(code)};

const styleEl = document.createElement("style");
const codeEl = document.createTextNode(code);
styleEl.type = 'text/css';

styleEl.appendChild(codeEl);
document.head.appendChild(styleEl);`;
  return wrapImportMeta({
    code: cssImportProxyCode,
    hmr,
    env: false,
    config
  });
}

let _cssModuleLoader;

async function generateCssModuleImportProxy({
  url,
  code,
  hmr,
  config
}) {
  _cssModuleLoader = _cssModuleLoader || new (require('css-modules-loader-core'))();
  const {
    injectableSource,
    exportTokens
  } = await _cssModuleLoader.load(code, url, undefined, () => {
    throw new Error('Imports in CSS Modules are not yet supported.');
  });
  return `${hmr ? `
import * as __SNOWPACK_HMR_API__ from '${getMetaUrlPath('hmr.js', config)}';
import.meta.hot = __SNOWPACK_HMR_API__.createHotContext(import.meta.url);
import.meta.hot.dispose(() => {
  document.head.removeChild(styleEl);
});\n` : ``}
export let code = ${JSON.stringify(injectableSource)};
let json = ${JSON.stringify(exportTokens)};
export default json;

const styleEl = document.createElement("style");
const codeEl = document.createTextNode(code);
styleEl.type = 'text/css';

styleEl.appendChild(codeEl);
document.head.appendChild(styleEl);`;
}

function generateDefaultImportProxy(url) {
  return `export default ${JSON.stringify(url)};`;
}

async function wrapImportProxy({
  url,
  code,
  hmr,
  config
}) {
  const {
    baseExt,
    expandedExt
  } = getExt(url);

  if (typeof code === 'string') {
    if (baseExt === '.json') {
      return generateJsonImportProxy({
        code,
        hmr,
        config
      });
    }

    if (baseExt === '.css') {
      // if proxying a CSS file, remove its source map (the path no longer applies)
      const sanitized = code.replace(/\/\*#\s*sourceMappingURL=[^/]+\//gm, '');
      return expandedExt.endsWith('.module.css') ? generateCssModuleImportProxy({
        url,
        code: sanitized,
        hmr,
        config
      }) : generateCssImportProxy({
        code: sanitized,
        hmr,
        config
      });
    }
  }

  return generateDefaultImportProxy(url);
}
function generateEnvModule(mode) {
  const envObject = getSnowpackPublicEnvVariables();
  envObject.MODE = mode;
  envObject.NODE_ENV = mode;
  return `export default ${JSON.stringify(envObject)};`;
}
const PUBLIC_ENV_REGEX = /^SNOWPACK_PUBLIC_.+/;

function getSnowpackPublicEnvVariables() {
  const envObject = _objectSpread2({}, process.env);

  for (const env of Object.keys(envObject)) {
    if (!PUBLIC_ENV_REGEX.test(env)) {
      delete envObject[env];
    }
  }

  return envObject;
}

var srcFileExtensionMapping = {
  '.mjs': '.js',
  '.jsx': '.js',
  '.ts': '.js',
  '.tsx': '.js',
  '.vue': '.js',
  '.svelte': '.js',
  '.mdx': '.js',
  '.svx': '.js',
  '.elm': '.js',
  '.yaml': '.json',
  '.toml': '.json',
  '.php': '.html',
  '.md': '.html',
  '.ejs': '.html',
  '.njk': '.html',
  '.scss': '.css',
  '.sass': '.css',
  '.less': '.css'
};

let esbuildService = null;
const IS_PREACT = /from\s+['"]preact['"]/;

function checkIsPreact(filePath, contents) {
  return filePath.endsWith('.jsx') && IS_PREACT.test(contents);
}

function getLoader(filePath) {
  const ext = path.extname(filePath);

  if (ext === '.mjs') {
    return 'js';
  }

  return ext.substr(1);
}

function esbuildPlugin(config, {
  input
}) {
  return {
    name: '@snowpack/plugin-esbuild',
    resolve: {
      input,
      output: ['.js']
    },

    async load({
      filePath
    }) {
      esbuildService = esbuildService || (await esbuild.startService());
      const contents = await fs.promises.readFile(filePath, 'utf-8');
      const isPreact = checkIsPreact(filePath, contents);
      const {
        js,
        jsSourceMap,
        warnings
      } = await esbuildService.transform(contents, {
        loader: getLoader(filePath),
        jsxFactory: isPreact ? 'h' : undefined,
        jsxFragment: isPreact ? 'Fragment' : undefined,
        sourcefile: filePath,
        sourcemap: config.buildOptions.sourceMaps
      });

      for (const warning of warnings) {
        logger.error(`${colors.bold('!')} ${filePath}
  ${warning.text}`);
      }

      return {
        '.js': {
          code: js || '',
          map: jsSourceMap
        }
      };
    },

    cleanup() {
      esbuildService && esbuildService.stop();
    }

  };
}

const CONFIG_NAME = 'snowpack';
const ALWAYS_EXCLUDE = ['**/node_modules/**/*', '**/.types/**/*']; // default settings

const DEFAULT_CONFIG = {
  exclude: ['__tests__/**/*', '**/*.@(spec|test).*'],
  plugins: [],
  alias: {},
  installOptions: {
    dest: 'web_modules',
    externalPackage: [],
    installTypes: false,
    polyfillNode: false,
    env: {},
    namedExports: [],
    rollup: {
      plugins: [],
      dedupe: []
    }
  },
  scripts: {},
  devOptions: {
    secure: false,
    hostname: 'localhost',
    port: 8080,
    open: 'default',
    out: 'build',
    fallback: 'index.html'
  },
  buildOptions: {
    baseUrl: '/',
    webModulesUrl: '/web_modules',
    clean: false,
    metaDir: '__snowpack__',
    minify: false,
    sourceMaps: false,
    watch: false
  }
};
const configSchema = {
  type: 'object',
  properties: {
    extends: {
      type: 'string'
    },
    install: {
      type: 'array',
      items: {
        type: 'string'
      }
    },
    exclude: {
      type: 'array',
      items: {
        type: 'string'
      }
    },
    plugins: {
      type: 'array'
    },
    webDependencies: {
      type: ['object'],
      additionalProperties: {
        type: 'string'
      }
    },
    scripts: {
      type: ['object'],
      additionalProperties: {
        type: 'string'
      }
    },
    alias: {
      type: 'object',
      additionalProperties: {
        type: 'string'
      }
    },
    devOptions: {
      type: 'object',
      properties: {
        secure: {
          type: 'boolean'
        },
        port: {
          type: 'number'
        },
        out: {
          type: 'string'
        },
        fallback: {
          type: 'string'
        },
        bundle: {
          type: 'boolean'
        },
        open: {
          type: 'string'
        },
        hmr: {
          type: 'boolean'
        }
      }
    },
    installOptions: {
      type: 'object',
      properties: {
        dest: {
          type: 'string'
        },
        externalPackage: {
          type: 'array',
          items: {
            type: 'string'
          }
        },
        treeshake: {
          type: 'boolean'
        },
        installTypes: {
          type: 'boolean'
        },
        polyfillNode: {
          type: 'boolean'
        },
        sourceMap: {
          oneOf: [{
            type: 'boolean'
          }, {
            type: 'string'
          }]
        },
        alias: {
          type: 'object',
          additionalProperties: {
            type: 'string'
          }
        },
        env: {
          type: 'object',
          additionalProperties: {
            oneOf: [{
              id: 'EnvVarString',
              type: 'string'
            }, {
              id: 'EnvVarNumber',
              type: 'number'
            }, {
              id: 'EnvVarTrue',
              type: 'boolean',
              enum: [true]
            }]
          }
        },
        rollup: {
          type: 'object',
          properties: {
            plugins: {
              type: 'array',
              items: {
                type: 'object'
              }
            },
            dedupe: {
              type: 'array',
              items: {
                type: 'string'
              }
            }
          }
        }
      }
    },
    buildOptions: {
      type: ['object'],
      properties: {
        baseUrl: {
          type: 'string'
        },
        clean: {
          type: 'boolean'
        },
        metaDir: {
          type: 'string'
        },
        minify: {
          type: 'boolean'
        },
        sourceMaps: {
          type: 'boolean'
        },
        watch: {
          type: 'boolean'
        }
      }
    },
    proxy: {
      type: 'object'
    }
  }
};
/**
 * Convert CLI flags to an incomplete Snowpack config representation.
 * We need to be careful about setting properties here if the flag value
 * is undefined, since the deep merge strategy would then overwrite good
 * defaults with 'undefined'.
 */

function expandCliFlags(flags) {
  const result = {
    installOptions: {},
    devOptions: {},
    buildOptions: {}
  };

  const relevantFlags = _objectWithoutProperties(flags, ["help", "version", "reload", "config"]);

  const CLI_ONLY_FLAGS = ['quiet', 'verbose'];

  for (const [flag, val] of Object.entries(relevantFlags)) {
    if (flag === '_' || flag.includes('-')) {
      continue;
    }

    if (configSchema.properties[flag]) {
      result[flag] = val;
      continue;
    }

    if (configSchema.properties.installOptions.properties[flag]) {
      result.installOptions[flag] = val;
      continue;
    }

    if (configSchema.properties.devOptions.properties[flag]) {
      result.devOptions[flag] = val;
      continue;
    }

    if (configSchema.properties.buildOptions.properties[flag]) {
      result.buildOptions[flag] = val;
      continue;
    }

    if (CLI_ONLY_FLAGS.includes(flag)) {
      continue;
    }

    logger.error(`Unknown CLI flag: "${flag}"`);
    process.exit(1);
  }

  if (result.installOptions.env) {
    result.installOptions.env = result.installOptions.env.reduce((acc, id) => {
      const index = id.indexOf('=');
      const [key, val] = index > 0 ? [id.substr(0, index), id.substr(index + 1)] : [id, true];
      acc[key] = val;
      return acc;
    }, {});
  }

  return result;
}
/** ensure extensions all have preceding dots */


function parseScript(script) {
  const [scriptType, extMatch] = script.toLowerCase().split(':');
  const [inputMatch, outputMatch] = extMatch ? extMatch.split('->') : [];
  const cleanInput = [...new Set(inputMatch.split(',').map(ext => `.${ext}`))];
  let cleanOutput = [];

  if (outputMatch) {
    cleanOutput = [...new Set(outputMatch.split(',').map(ext => `.${ext}`))];
  } else if (cleanInput[0] === '.svelte') {
    cleanOutput = ['.js', '.css'];
  } else if (cleanInput[0] === '.vue') {
    cleanOutput = ['.js', '.css'];
  } else if (cleanInput.length > 0) {
    cleanOutput = Array.from(new Set(cleanInput.map(ext => srcFileExtensionMapping[ext] || ext)));
  }

  return {
    scriptType,
    input: cleanInput,
    output: cleanOutput
  };
}
/** load and normalize plugins from config */


function loadPlugins(config) {
  const plugins = [];

  function execPluginFactory(pluginFactory, pluginOptions) {
    let plugin = null;
    plugin = pluginFactory(config, pluginOptions);
    return plugin;
  }

  function loadPluginFromScript(specifier) {
    try {
      const pluginLoc = require.resolve(specifier, {
        paths: [process.cwd()]
      });

      return execPluginFactory(require(pluginLoc)); // no plugin options to load because we’re loading from a string
    } catch (err) {// ignore
    }
  }

  function loadPluginFromConfig(name, options) {
    const pluginLoc = require.resolve(name, {
      paths: [process.cwd()]
    });

    const pluginRef = require(pluginLoc);

    let plugin;

    try {
      plugin = typeof pluginRef.default === 'function' ? pluginRef.default : pluginRef;
      if (typeof plugin !== 'function') logger.error(`plugin ${name} doesn’t return function`);
      plugin = execPluginFactory(plugin, options);
    } catch (err) {
      logger.error(err.toString() || err);
      throw err;
    }

    plugin.name = plugin.name || name; // Legacy support: Map the new load() interface to the old build() interface

    const {
      build,
      bundle
    } = plugin;

    if (build) {
      plugin.load = async options => {
        const result = await build(_objectSpread2(_objectSpread2({}, options), {}, {
          contents: await readFile(options.filePath)
        })).catch(err => {
          logger.error(`[${plugin.name}] There was a problem running this older plugin. Please update the plugin to the latest version.`);
          throw err;
        });

        if (!result) {
          return null;
        }

        if (result.resources) {
          return {
            '.js': result.result,
            '.css': result.resources.css
          };
        }

        return result.result;
      };
    } // Legacy support: Map the new optimize() interface to the old bundle() interface


    if (bundle) {
      plugin.optimize = async options => {
        return bundle({
          srcDirectory: options.buildDirectory,
          destDirectory: options.buildDirectory,
          // @ts-ignore internal API only
          log: options.log,
          // It turns out, this was more or less broken (included all files, not just JS).
          // Confirmed no plugins are using this now, so safe to use an empty array.
          jsFilePaths: []
        }).catch(err => {
          logger.error(`[${plugin.name}] There was a problem running this older plugin. Please update the plugin to the latest version.`);
          throw err;
        });
      };
    }

    if (!plugin.resolve && plugin.defaultBuildScript && plugin.defaultBuildScript.startsWith('build:')) {
      const {
        input,
        output
      } = parseScript(plugin.defaultBuildScript);
      plugin.resolve = {
        input,
        output
      };
    } else if (plugin.resolve) {
      const {
        input,
        output
      } = plugin.resolve;
      plugin.resolve = {
        input,
        output
      };
    }

    validatePlugin(plugin);
    return plugin;
  } // 1. require & load config.scripts
  // TODO: deprecate scripts and move out of this function


  Object.entries(config.scripts).forEach(([target, cmd]) => {
    const {
      scriptType,
      input,
      output
    } = parseScript(target);

    if (config.plugins.some(p => (Array.isArray(p) ? p[0] : p) === cmd)) {
      handleConfigError(`[${cmd}]: loaded in both \`scripts\` and \`plugins\`. Please choose one (preferably \`plugins\`).`);
    }

    switch (scriptType) {
      case 'run':
        {
          if (target.endsWith('::watch')) {
            break;
          }

          const watchCmd = config.scripts[target + '::watch'];
          plugins.push(execPluginFactory(runScriptPlugin, {
            cmd,
            watch: watchCmd || cmd
          }));
          break;
        }

      case 'build':
        {
          plugins.push(execPluginFactory(buildScriptPlugin, {
            input,
            output,
            cmd
          }));
          break;
        }

      case 'bundle':
        {
          plugins.push(loadPluginFromScript(cmd));
          break;
        }
    }
  }); // 2. config.plugins

  config.plugins.forEach(ref => {
    const pluginName = Array.isArray(ref) ? ref[0] : ref;
    const pluginOptions = Array.isArray(ref) ? ref[1] : {};
    const plugin = loadPluginFromConfig(pluginName, pluginOptions);
    logger.debug(`loaded plugin: ${pluginName}`);
    plugins.push(plugin);
  }); // add internal JS handler plugin if none specified

  const needsDefaultPlugin = new Set(['.mjs', '.jsx', '.ts', '.tsx']);
  plugins.filter(({
    resolve
  }) => !!resolve).reduce((arr, a) => arr.concat(a.resolve.input), []).forEach(ext => needsDefaultPlugin.delete(ext));

  if (needsDefaultPlugin.size > 0) {
    plugins.unshift(execPluginFactory(esbuildPlugin, {
      input: [...needsDefaultPlugin]
    }));
  }

  const extensionMap = plugins.reduce((map, {
    resolve
  }) => {
    if (resolve) {
      for (const inputExt of resolve.input) {
        map[inputExt] = resolve.output[0];
      }
    }

    return map;
  }, {});
  return {
    plugins,
    extensionMap
  };
}
/**
 * Convert deprecated proxy scripts to
 * FUTURE: Remove this on next major release
 */


function handleLegacyProxyScripts(config) {
  for (const scriptId in config.scripts) {
    if (!scriptId.startsWith('proxy:')) {
      continue;
    }

    const cmdArr = config.scripts[scriptId].split(/\s+/);

    if (cmdArr[0] !== 'proxy') {
      handleConfigError(`scripts[${scriptId}] must use the proxy command`);
    }

    cmdArr.shift();
    const {
      to,
      _
    } = yargs(cmdArr);

    if (_.length !== 1) {
      handleConfigError(`scripts[${scriptId}] must use the format: "proxy http://SOME.URL --to /PATH"`);
    }

    if (to && to[0] !== '/') {
      handleConfigError(`scripts[${scriptId}]: "--to ${to}" must be a URL path, and start with a "/"`);
    }

    const {
      toUrl,
      fromUrl
    } = {
      fromUrl: _[0],
      toUrl: to
    };

    if (config.proxy[toUrl]) {
      handleConfigError(`scripts[${scriptId}]: Cannot overwrite proxy[${toUrl}].`);
    }

    config.proxy[toUrl] = fromUrl;
    delete config.scripts[scriptId];
  }

  return config;
}

function normalizeProxies(proxies) {
  return Object.entries(proxies).map(([pathPrefix, options]) => {
    if (typeof options !== 'string') {
      return [pathPrefix, _objectSpread2({
        //@ts-ignore - Seems to be a strange 3.9.x bug
        on: {}
      }, options)];
    }

    return [pathPrefix, {
      on: {
        proxyReq: (proxyReq, req) => {
          const proxyPath = proxyReq.path.split(req.url)[0];
          proxyReq.path = proxyPath + req.url.replace(pathPrefix, '');
        }
      },
      target: options,
      changeOrigin: true,
      secure: false
    }];
  });
}

function normalizeMount(config) {
  const mountedDirs = config.mount || {};

  for (const [target, cmd] of Object.entries(config.scripts)) {
    if (target.startsWith('mount:')) {
      const cmdArr = cmd.split(/\s+/);

      if (cmdArr[0] !== 'mount') {
        handleConfigError(`scripts[${target}] must use the mount command`);
      }

      cmdArr.shift();
      const {
        to,
        _
      } = yargs(cmdArr);

      if (_.length !== 1) {
        handleConfigError(`scripts[${target}] must use the format: "mount dir [--to /PATH]"`);
      }

      if (target === 'mount:web_modules') {
        config.buildOptions.webModulesUrl = to;
      } else {
        mountedDirs[cmdArr[0]] = to || `/${cmdArr[0]}`;
      }
    }
  }

  for (const [mountDir, mountUrl] of Object.entries(mountedDirs)) {
    const fromDisk = path.posix.normalize(mountDir + '/');
    delete mountedDirs[mountDir];
    mountedDirs[fromDisk] = mountUrl;

    if (mountUrl[0] !== '/') {
      handleConfigError(`mount[${mountDir}]: Value "${mountUrl}" must be a URL path, and start with a "/"`);
    }
  } // if no mounted directories, mount the root directory to the base URL


  if (!Object.keys(mountedDirs).length) {
    mountedDirs['.'] = '/';
  }

  return mountedDirs;
}

function normalizeAlias(config, createMountAlias) {
  const cwd = process.cwd();
  const cleanAlias = config.alias || {};

  if (createMountAlias) {
    for (const mountDir of Object.keys(config.mount)) {
      if (mountDir !== '.') {
        cleanAlias[addTrailingSlash(mountDir)] = addTrailingSlash(`./${mountDir}`);
      }
    }
  }

  for (const [target, replacement] of Object.entries(config.alias)) {
    if (replacement === '.' || replacement === '..' || replacement.startsWith('./') || replacement.startsWith('../') || replacement.startsWith('/')) {
      delete cleanAlias[target];
      cleanAlias[addTrailingSlash(target)] = addTrailingSlash(path.resolve(cwd, replacement));
    }
  }

  return cleanAlias;
}
/** resolve --dest relative to cwd, etc. */


function normalizeConfig(config) {
  const cwd = process.cwd();
  config.knownEntrypoints = config.install || [];
  config.installOptions.dest = path.resolve(cwd, config.installOptions.dest);
  config.devOptions.out = path.resolve(cwd, config.devOptions.out);
  config.exclude = Array.from(new Set([...ALWAYS_EXCLUDE, `${config.devOptions.out}/**/*`, ...config.exclude]));

  if (!config.proxy) {
    config.proxy = {};
  } // normalize config URL/path values


  config.buildOptions.baseUrl = addTrailingSlash(config.buildOptions.baseUrl);
  config.buildOptions.webModulesUrl = addLeadingSlash(config.buildOptions.webModulesUrl);
  config.buildOptions.metaDir = removeLeadingSlash(removeTrailingSlash(config.buildOptions.metaDir));
  const isLegacyMountConfig = !config.mount;
  config = handleLegacyProxyScripts(config);
  config.proxy = normalizeProxies(config.proxy);
  config.mount = normalizeMount(config);
  config.alias = normalizeAlias(config, isLegacyMountConfig); // new pipeline

  const {
    plugins,
    extensionMap
  } = loadPlugins(config);
  config.plugins = plugins;
  config._extensionMap = extensionMap; // If any plugins defined knownEntrypoints, add them here

  for (const {
    knownEntrypoints
  } of config.plugins) {
    if (knownEntrypoints) {
      config.knownEntrypoints = config.knownEntrypoints.concat(knownEntrypoints);
    }
  }

  plugins.forEach(plugin => {
    if (plugin.config) {
      plugin.config(config);
    }
  });
  return config;
}

function handleConfigError(msg) {
  logger.error(msg);
  process.exit(1);
}

function handleValidationErrors(filepath, errors) {
  logger.error(`! ${filepath || 'Configuration error'}
${errors.map(err => `    - ${err.toString()}`).join('\n')}
    See https://www.snowpack.dev/#configuration for more info.`);
  process.exit(1);
}

function handleDeprecatedConfigError(mainMsg, ...msgs) {
  logger.error(`${mainMsg}
${msgs.join('\n')}
See https://www.snowpack.dev/#configuration for more info.`);
  process.exit(1);
}

function validateConfigAgainstV1(rawConfig, cliFlags) {
  var _rawConfig$installOpt, _rawConfig$installOpt2, _rawConfig$installOpt3, _rawConfig$installOpt4, _rawConfig$buildOptio, _rawConfig$devOptions, _rawConfig$installOpt5, _rawConfig$installOpt6, _rawConfig$installOpt7, _rawConfig$installOpt8, _rawConfig$installOpt9, _rawConfig$installOpt10;

  // Moved!
  if (rawConfig.dedupe || cliFlags.dedupe) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `dedupe` is now `installOptions.rollup.dedupe`.');
  }

  if (rawConfig.namedExports) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `rollup.namedExports` is no longer required. See also: installOptions.namedExports');
  }

  if ((_rawConfig$installOpt = rawConfig.installOptions) === null || _rawConfig$installOpt === void 0 ? void 0 : (_rawConfig$installOpt2 = _rawConfig$installOpt.rollup) === null || _rawConfig$installOpt2 === void 0 ? void 0 : _rawConfig$installOpt2.namedExports) {
    delete rawConfig.installOptions.rollup.namedExports;
    logger.error('[Snowpack v2.3.0] `rollup.namedExports` is no longer required. See also: installOptions.namedExports');
  }

  if (rawConfig.rollup) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] top-level `rollup` config is now `installOptions.rollup`.');
  }

  if (((_rawConfig$installOpt3 = rawConfig.installOptions) === null || _rawConfig$installOpt3 === void 0 ? void 0 : _rawConfig$installOpt3.include) || cliFlags.include) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.include` is now handled via "mount" build scripts!');
  }

  if ((_rawConfig$installOpt4 = rawConfig.installOptions) === null || _rawConfig$installOpt4 === void 0 ? void 0 : _rawConfig$installOpt4.exclude) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.exclude` is now `exclude`.');
  }

  if (Array.isArray(rawConfig.webDependencies)) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] The `webDependencies` array is now `install`.');
  }

  if (rawConfig.knownEntrypoints) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `knownEntrypoints` is now `install`.');
  }

  if (rawConfig.entrypoints) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `entrypoints` is now `install`.');
  }

  if (rawConfig.include) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] All files are now included by default. "include" config is safe to remove.', 'Whitelist & include specific folders via "mount" build scripts.');
  } // Replaced!


  if (rawConfig.source || cliFlags.source) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `source` is now detected automatically, this config is safe to remove.');
  }

  if (rawConfig.stat || cliFlags.stat) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `stat` is now the default output, this config is safe to remove.');
  }

  if (rawConfig.scripts && Object.keys(rawConfig.scripts).filter(k => k.startsWith('lintall')).length > 0) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `scripts["lintall:..."]` has been renamed to scripts["run:..."]');
  }

  if (rawConfig.scripts && Object.keys(rawConfig.scripts).filter(k => k.startsWith('plugin:`')).length > 0) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `scripts["plugin:..."]` have been renamed to scripts["build:..."].');
  }

  if ((_rawConfig$buildOptio = rawConfig.buildOptions) === null || _rawConfig$buildOptio === void 0 ? void 0 : _rawConfig$buildOptio.minify) {
    handleDeprecatedConfigError('[Snowpack 2.11.0] `buildOptions.minify` has moved to package "@snowpack/plugin-optimize". Install it and include as a plugin in your Snowpack config file.');
  } // Removed!


  if ((_rawConfig$devOptions = rawConfig.devOptions) === null || _rawConfig$devOptions === void 0 ? void 0 : _rawConfig$devOptions.dist) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `devOptions.dist` is no longer required. This config is safe to remove.', `If you'd still like to host your src/ directory at the "/_dist/*" URL, create a mount script:',
      '    {"scripts": {"mount:src": "mount src --to /_dist_"}} `);
  }

  if (rawConfig.hash || cliFlags.hash) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.hash` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt5 = rawConfig.installOptions) === null || _rawConfig$installOpt5 === void 0 ? void 0 : _rawConfig$installOpt5.nomodule) || cliFlags.nomodule) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.nomodule` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt6 = rawConfig.installOptions) === null || _rawConfig$installOpt6 === void 0 ? void 0 : _rawConfig$installOpt6.nomoduleOutput) || cliFlags.nomoduleOutput) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.nomoduleOutput` has been replaced by `snowpack build`.');
  }

  if (((_rawConfig$installOpt7 = rawConfig.installOptions) === null || _rawConfig$installOpt7 === void 0 ? void 0 : _rawConfig$installOpt7.babel) || cliFlags.babel) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.babel` has been replaced by `snowpack build`.');
  }

  if ((_rawConfig$installOpt8 = rawConfig.installOptions) === null || _rawConfig$installOpt8 === void 0 ? void 0 : _rawConfig$installOpt8.optimize) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.optimize` has been replaced by `snowpack build` minification.');
  }

  if (((_rawConfig$installOpt9 = rawConfig.installOptions) === null || _rawConfig$installOpt9 === void 0 ? void 0 : _rawConfig$installOpt9.strict) || cliFlags.strict) {
    handleDeprecatedConfigError('[Snowpack v1 -> v2] `installOptions.strict` is no longer supported.');
  }

  if ((_rawConfig$installOpt10 = rawConfig.installOptions) === null || _rawConfig$installOpt10 === void 0 ? void 0 : _rawConfig$installOpt10.alias) {
    handleDeprecatedConfigError('[New in v2.7] `installOptions.alias` has been moved to a top-level `alias` config. (https://snowpack.dev#all-config-options)');
  }
}

function validatePlugin(plugin) {
  const pluginName = plugin.name;

  if (plugin.resolve && !plugin.load) {
    handleConfigError(`[${pluginName}] "resolve" config found but "load()" method missing.`);
  }

  if (!plugin.resolve && plugin.load) {
    handleConfigError(`[${pluginName}] "load" method found but "resolve()" config missing.`);
  }

  if (plugin.resolve && !Array.isArray(plugin.resolve.input)) {
    handleConfigError(`[${pluginName}] "resolve.input" should be an array of input file extensions.`);
  }

  if (plugin.resolve && !Array.isArray(plugin.resolve.output)) {
    handleConfigError(`[${pluginName}] "resolve.output" should be an array of output file extensions.`);
  }
}

function validatePluginLoadResult(plugin, result) {
  const pluginName = plugin.name;

  if (!result) {
    return;
  }

  const isValidSingleResultType = typeof result === 'string' || Buffer.isBuffer(result);

  if (isValidSingleResultType && plugin.resolve.output.length !== 1) {
    handleConfigError(`[plugin=${pluginName}] "load()" returned a string, but "resolve.output" contains multiple possible outputs. If multiple outputs are expected, the object return format is required.`);
  }

  const unexpectedOutput = typeof result === 'object' && Object.keys(result).find(fileExt => !plugin.resolve.output.includes(fileExt));

  if (unexpectedOutput) {
    handleConfigError(`[plugin=${pluginName}] "load()" returned entry "${unexpectedOutput}" not found in "resolve.output": ${plugin.resolve.output}`);
  }
}
function createConfiguration(config) {
  const {
    errors: validationErrors
  } = jsonschema.validate(config, configSchema, {
    propertyName: CONFIG_NAME,
    allowUnknownAttributes: false
  });

  if (validationErrors.length > 0) {
    return [validationErrors, undefined];
  }

  const mergedConfig = merge.all([DEFAULT_CONFIG, config]);
  return [null, normalizeConfig(mergedConfig)];
}
function loadAndValidateConfig(flags, pkgManifest) {
  const explorerSync = cosmiconfig.cosmiconfigSync(CONFIG_NAME, {
    // only support these 4 types of config for now
    searchPlaces: ['package.json', 'snowpack.config.cjs', 'snowpack.config.js', 'snowpack.config.json'],
    // don't support crawling up the folder tree:
    stopDir: path.dirname(process.cwd())
  });
  let result; // if user specified --config path, load that

  if (flags.config) {
    result = explorerSync.load(path.resolve(process.cwd(), flags.config));

    if (!result) {
      handleConfigError(`Could not locate Snowpack config at ${flags.config}`);
    }
  } // If no config was found above, search for one.


  result = result || explorerSync.search(); // If still no config found, assume none exists and use the default config.

  if (!result || !result.config || result.isEmpty) {
    result = {
      config: _objectSpread2({}, DEFAULT_CONFIG)
    };
  } // validate against schema; throw helpful user if invalid


  const config = result.config;
  validateConfigAgainstV1(config, flags);
  const cliConfig = expandCliFlags(flags);
  let extendConfig = {};

  if (config.extends) {
    const extendConfigLoc = config.extends.startsWith('.') ? path.resolve(path.dirname(result.filepath), config.extends) : require.resolve(config.extends, {
      paths: [process.cwd()]
    });
    const extendResult = explorerSync.load(extendConfigLoc);

    if (!extendResult) {
      handleConfigError(`Could not locate Snowpack config at ${flags.config}`);
      process.exit(1);
    }

    extendConfig = extendResult.config;
    const extendValidation = jsonschema.validate(extendConfig, configSchema, {
      allowUnknownAttributes: false,
      propertyName: CONFIG_NAME
    });

    if (extendValidation.errors && extendValidation.errors.length > 0) {
      handleValidationErrors(result.filepath, extendValidation.errors);
      process.exit(1);
    }

    if (extendConfig.plugins) {
      const extendConfigDir = path.dirname(extendConfigLoc);
      extendConfig.plugins = extendConfig.plugins.map(plugin => {
        const name = Array.isArray(plugin) ? plugin[0] : plugin;
        const absName = path.isAbsolute(name) ? name : require.resolve(name, {
          paths: [extendConfigDir]
        });

        if (Array.isArray(plugin)) {
          plugin.splice(0, 1, absName);
          return plugin;
        }

        return absName;
      });
    }
  } // if valid, apply config over defaults


  const mergedConfig = merge.all([pkgManifest.homepage ? {
    buildOptions: {
      baseUrl: pkgManifest.homepage
    }
  } : {}, extendConfig, {
    webDependencies: pkgManifest.webDependencies
  }, config, cliConfig]);

  for (const webDependencyName of Object.keys(mergedConfig.webDependencies || {})) {
    if (pkgManifest.dependencies && pkgManifest.dependencies[webDependencyName]) {
      handleConfigError(`"${webDependencyName}" is included in "webDependencies". Please remove it from your package.json "dependencies" config.`);
    }

    if (pkgManifest.devDependencies && pkgManifest.devDependencies[webDependencyName]) {
      handleConfigError(`"${webDependencyName}" is included in "webDependencies". Please remove it from your package.json "devDependencies" config.`);
    }
  }

  const [validationErrors, configResult] = createConfiguration(mergedConfig);

  if (validationErrors) {
    handleValidationErrors(result.filepath, validationErrors);
    process.exit(1);
  }

  return configResult;
}

function getInputsFromOutput(fileLoc, plugins) {
  const srcFile = replaceExt(fileLoc, '.map', ''); // if this is a .map file, try loading source

  const {
    baseExt
  } = getExt(srcFile);
  const potentialInputs = new Set([srcFile]);

  for (const plugin of plugins) {
    if (plugin.resolve && plugin.resolve.output.includes(baseExt)) {
      plugin.resolve.input.forEach(input => potentialInputs.add(replaceExt(srcFile, baseExt, input)));
    }
  }

  return Array.from(potentialInputs);
}
/**
 * Build Plugin First Pass: If a plugin defines a
 * `resolve` object, check it against the current
 * file's extension. If it matches, call the load()
 * functon and return it's result.
 *
 * If no match is found, fall back to just reading
 * the file from disk and return it.
 */

async function runPipelineLoadStep(srcPath, {
  isDev,
  isHmrEnabled,
  isExitOnBuild,
  plugins,
  sourceMaps
}) {
  const srcExt = getExt(srcPath).baseExt;

  for (const step of plugins) {
    if (!step.resolve || !step.resolve.input.includes(srcExt)) {
      continue;
    }

    if (!step.load) {
      continue;
    }

    try {
      const debugPath = path.relative(process.cwd(), srcPath);
      logger.debug(`load() starting… [${debugPath}]`, {
        name: step.name
      });
      const result = await step.load({
        fileExt: srcExt,
        filePath: srcPath,
        isDev,
        isHmrEnabled
      });
      logger.debug(`✔ load() success [${debugPath}]`, {
        name: step.name
      });
      validatePluginLoadResult(step, result);

      if (typeof result === 'string' || Buffer.isBuffer(result)) {
        const mainOutputExt = step.resolve.output[0];
        return {
          [mainOutputExt]: {
            code: result
          }
        };
      } else if (result && typeof result === 'object') {
        Object.keys(result).forEach(ext => {
          const output = result[ext]; // normalize to {code, map} format

          if (typeof output === 'string') result[ext] = {
            code: output
          }; // ensure source maps are strings (it’s easy for plugins to pass back a JSON object)

          if (result[ext].map && typeof result[ext].map === 'object') result[ext].map = JSON.stringify(result[ext].map); // if source maps disabled, don’t return any

          if (!sourceMaps) result[ext].map = undefined;
        });
        return result;
      }
    } catch (err) {
      // note: for many plugins like Babel, `err.toString()` is needed to display full output
      logger.error(err.toString() || err, {
        name: step.name
      });

      if (isExitOnBuild) {
        process.exit(1);
      }
    }
  }

  return {
    [srcExt]: {
      code: await readFile(srcPath)
    }
  };
}
/**
 * Build Plugin Second Pass: If a plugin defines a
 * transform() method,call it. Transform cannot change
 * the file extension, and was designed to run on
 * every file type and return null/undefined if no
 * change needed.
 */


async function runPipelineTransformStep(output, srcPath, {
  isDev,
  isExitOnBuild,
  plugins,
  sourceMaps
}) {
  const srcExt = getExt(srcPath).baseExt;
  const rootFilePath = srcPath.replace(srcExt, '');
  const rootFileName = path.basename(rootFilePath);

  for (const step of plugins) {
    if (!step.transform) {
      continue;
    }

    try {
      for (const destExt of Object.keys(output)) {
        const destBuildFile = output[destExt];
        const {
          code
        } = destBuildFile;
        const fileName = rootFileName + destExt;
        const filePath = rootFilePath + destExt;
        const debugPath = path.relative(process.cwd(), filePath);
        logger.debug(`transform() starting… [${debugPath}]`, {
          name: step.name
        });
        const result = await step.transform({
          contents: code,
          isDev,
          fileExt: destExt,
          id: filePath,
          // @ts-ignore: Deprecated
          filePath: fileName,
          // @ts-ignore: Deprecated
          urlPath: `./${path.basename(rootFileName + destExt)}`
        });
        logger.debug(`✔ transform() success [${debugPath}]`, {
          name: step.name
        }); // if step returned a value, only update code (don’t touch .map)

        if (typeof result === 'string' || Buffer.isBuffer(result)) {
          output[destExt].code = result;
          output[destExt].map = undefined;
        } else if (result && typeof result === 'object' && result.result) {
          output[destExt].code = result.result;
          output[destExt].map = undefined;
        } // if source maps disabled, don’t return any


        if (!sourceMaps) output[destExt].map = undefined;
      }
    } catch (err) {
      // note: for many plugins like Babel, `err.toString()` is needed to display full output
      logger.error(err.toString() || err, {
        name: step.name
      });

      if (isExitOnBuild) {
        process.exit(1);
      }
    }
  }

  return output;
}

async function runPipelineOptimizeStep(buildDirectory, {
  plugins
}) {
  for (const step of plugins) {
    if (!step.optimize) {
      continue;
    }

    try {
      logger.debug('optimize() starting…', {
        name: step.name
      });
      await step.optimize({
        buildDirectory,
        // @ts-ignore: internal API only
        log: msg => {
          logger.info(msg, {
            name: step.name
          });
        }
      });
      logger.debug('✔ optimize() success', {
        name: step.name
      });
    } catch (err) {
      logger.error(err.toString() || err, {
        name: step.name
      });
      process.exit(1); // exit on error
    }
  }

  return null;
}
async function runPipelineCleanupStep({
  plugins
}) {
  for (const step of plugins) {
    if (!step.cleanup) {
      continue;
    }

    await step.cleanup();
  }
}
/** Core Snowpack file pipeline builder */

async function buildFile(srcPath, buildFileOptions) {
  // Pass 1: Find the first plugin to load this file, and return the result
  const loadResult = await runPipelineLoadStep(srcPath, buildFileOptions); // Pass 2: Pass that result through every plugin transform() method.

  const transformResult = await runPipelineTransformStep(loadResult, srcPath, buildFileOptions); // Return the final build result.

  return transformResult;
}

const cwd$1 = process.cwd();
/** Perform a file disk lookup for the requested import specifier. */

function getImportStats(dirLoc, spec) {
  const importedFileOnDisk = path.resolve(dirLoc, spec);

  try {
    return fs__default.statSync(importedFileOnDisk);
  } catch (err) {// file doesn't exist, that's fine
  }

  return false;
}
/** Resolve an import based on the state of the file/folder found on disk. */

function resolveSourceSpecifier(spec, stats, config) {
  if (stats && stats.isDirectory()) {
    const trailingSlash = spec.endsWith('/') ? '' : '/';
    spec = spec + trailingSlash + 'index.js';
  } else if (!stats && !spec.endsWith('.js') && !spec.endsWith('.css')) {
    spec = spec + '.js';
  }

  const {
    baseExt
  } = getExt(spec);
  const extToReplace = config._extensionMap[baseExt] || srcFileExtensionMapping[baseExt];

  if (extToReplace) {
    spec = replaceExt(spec, baseExt, extToReplace);
  }

  return spec;
}
/**
 * Create a import resolver function, which converts any import relative to the given file at "fileLoc"
 * to a proper URL. Returns false if no matching import was found, which usually indicates a package
 * not found in the import map.
 */


function createImportResolver({
  fileLoc,
  dependencyImportMap,
  config
}) {
  return function importResolver(spec) {
    if (URL_HAS_PROTOCOL_REGEX.test(spec)) {
      return spec;
    }

    if (spec.startsWith('/') || spec.startsWith('./') || spec.startsWith('../')) {
      const importStats = getImportStats(path.dirname(fileLoc), spec);
      spec = resolveSourceSpecifier(spec, importStats, config);
      return spec;
    }

    const aliasEntry = findMatchingAliasEntry(config, spec);

    if (aliasEntry && aliasEntry.type === 'path') {
      const {
        from,
        to
      } = aliasEntry;
      let result = spec.replace(from, to);
      const importStats = getImportStats(cwd$1, result);
      result = resolveSourceSpecifier(result, importStats, config); // replace Windows backslashes at the end, after resolution

      result = relativeURL(path.dirname(fileLoc), result);
      return result;
    }

    if (dependencyImportMap) {
      // NOTE: We don't need special handling for an alias here, since the aliased "from"
      // is already the key in the import map. The aliased "to" value is also an entry.
      const importMapEntry = dependencyImportMap.imports[spec];

      if (importMapEntry) {
        return path.posix.resolve(config.buildOptions.webModulesUrl, importMapEntry);
      }
    }

    return false;
  };
}

const {
  parse
} = require('es-module-lexer');

function spliceString(source, withSlice, start, end) {
  return source.slice(0, start) + (withSlice || '') + source.slice(end);
}

async function scanCodeImportsExports(code) {
  const [imports] = await parse(code);
  return imports.filter(imp => {
    //imp.d = -2 = import.meta.url = we can skip this for now
    if (imp.d === -2) {
      return false;
    } // imp.d > -1 === dynamic import


    if (imp.d > -1) {
      const importStatement = code.substring(imp.s, imp.e);
      return !!matchDynamicImportValue(importStatement);
    }

    return true;
  });
}
async function transformEsmImports(_code, replaceImport) {
  const imports = await scanCodeImportsExports(_code);
  let rewrittenCode = _code;

  for (const imp of imports.reverse()) {
    let spec = rewrittenCode.substring(imp.s, imp.e);

    if (imp.d > -1) {
      spec = matchDynamicImportValue(spec) || '';
    }

    let rewrittenImport = replaceImport(spec);

    if (imp.d > -1) {
      rewrittenImport = JSON.stringify(rewrittenImport);
    }

    rewrittenCode = spliceString(rewrittenCode, rewrittenImport, imp.s, imp.e);
  }

  return rewrittenCode;
}

async function transformHtmlImports(code, replaceImport) {
  let rewrittenCode = code;
  let match;
  const importRegex = new RegExp(HTML_JS_REGEX);

  while (match = importRegex.exec(rewrittenCode)) {
    const [, scriptTag, scriptCode] = match; // Only transform a script element if it contains inlined code / is not empty.

    if (scriptCode.trim()) {
      rewrittenCode = spliceString(rewrittenCode, await transformEsmImports(scriptCode, replaceImport), match.index + scriptTag.length, match.index + scriptTag.length + scriptCode.length);
    }
  }

  return rewrittenCode;
}

async function transformCssImports(code, replaceImport) {
  let rewrittenCode = code;
  let match;
  const importRegex = new RegExp(CSS_REGEX);

  while (match = importRegex.exec(rewrittenCode)) {
    const [fullMatch, spec] = match; // Only transform a script element if it contains inlined code / is not empty.

    rewrittenCode = spliceString(rewrittenCode, `@import "${replaceImport(spec)}";`, match.index, match.index + fullMatch.length);
  }

  return rewrittenCode;
}

async function transformFileImports({
  baseExt,
  contents
}, replaceImport) {
  if (baseExt === '.js') {
    return transformEsmImports(contents, replaceImport);
  }

  if (baseExt === '.html') {
    return transformHtmlImports(contents, replaceImport);
  }

  if (baseExt === '.css') {
    return transformCssImports(contents, replaceImport);
  }

  throw new Error(`Incompatible filetype: cannot scan ${baseExt} files for ESM imports. This is most likely an error within Snowpack.`);
}

const DEFAULT_PORT = 12321;
class EsmHmrEngine {
  constructor(options = {}) {
    this.clients = new Set();
    this.dependencyTree = new Map();
    this.wsUrl = `ws://localhost:${DEFAULT_PORT}`;
    const wss = options.server ? new WebSocket.Server({
      noServer: true
    }) : new WebSocket.Server({
      port: DEFAULT_PORT
    });

    if (options.server) {
      options.server.on('upgrade', (req, socket, head) => {
        // Only handle upgrades to ESM-HMR requests, ignore others.
        if (req.headers['sec-websocket-protocol'] !== 'esm-hmr') {
          return;
        }

        wss.handleUpgrade(req, socket, head, client => {
          wss.emit('connection', client, req);
        });
      });
    }

    wss.on('connection', client => {
      this.connectClient(client);
      this.registerListener(client);
    });
  }

  registerListener(client) {
    client.on('message', data => {
      const message = JSON.parse(data.toString());

      if (message.type === 'hotAccept') {
        const entry = this.getEntry(message.id, true);
        entry.isHmrAccepted = true;
        entry.isHmrEnabled = true;
      }
    });
  }

  createEntry(sourceUrl) {
    const newEntry = {
      dependencies: new Set(),
      dependents: new Set(),
      needsReplacement: false,
      needsReplacementCount: 0,
      isHmrEnabled: false,
      isHmrAccepted: false
    };
    this.dependencyTree.set(sourceUrl, newEntry);
    return newEntry;
  }

  getEntry(sourceUrl, createIfNotFound = false) {
    const result = this.dependencyTree.get(sourceUrl);

    if (result) {
      return result;
    }

    if (createIfNotFound) {
      return this.createEntry(sourceUrl);
    }

    return null;
  }

  setEntry(sourceUrl, imports, isHmrEnabled = false) {
    const result = this.getEntry(sourceUrl, true);
    const outdatedDependencies = new Set(result.dependencies);
    result.isHmrEnabled = isHmrEnabled;

    for (const importUrl of imports) {
      this.addRelationship(sourceUrl, importUrl);
      outdatedDependencies.delete(importUrl);
    }

    for (const importUrl of outdatedDependencies) {
      this.removeRelationship(sourceUrl, importUrl);
    }
  }

  removeRelationship(sourceUrl, importUrl) {
    let importResult = this.getEntry(importUrl);
    importResult && importResult.dependents.delete(sourceUrl);
    const sourceResult = this.getEntry(sourceUrl);
    sourceResult && sourceResult.dependencies.delete(importUrl);
  }

  addRelationship(sourceUrl, importUrl) {
    if (importUrl !== sourceUrl) {
      let importResult = this.getEntry(importUrl, true);
      importResult.dependents.add(sourceUrl);
      const sourceResult = this.getEntry(sourceUrl, true);
      sourceResult.dependencies.add(importUrl);
    }
  }

  markEntryForReplacement(entry, state) {
    if (state) {
      entry.needsReplacementCount++;
    } else {
      entry.needsReplacementCount--;
    }

    entry.needsReplacement = !!entry.needsReplacementCount;
  }

  broadcastMessage(data) {
    this.clients.forEach(client => {
      if (client.readyState === WebSocket.OPEN) {
        client.send(JSON.stringify(data));
      } else {
        this.disconnectClient(client);
      }
    });
  }

  connectClient(client) {
    this.clients.add(client);
  }

  disconnectClient(client) {
    client.terminate();
    this.clients.delete(client);
  }

  disconnectAllClients() {
    for (const client of this.clients) {
      this.disconnectClient(client);
    }
  }

}

const CONCURRENT_WORKERS = require('os').cpus().length;

let hmrEngine = null;

function getIsHmrEnabled(config) {
  return config.buildOptions.watch && !!config.devOptions.hmr;
}

async function installOptimizedDependencies(scannedFiles, installDest, commandOptions) {
  var _commandOptions$confi;

  const installConfig = merge__default(commandOptions.config, {
    installOptions: {
      dest: installDest,
      env: {
        NODE_ENV: process.env.NODE_ENV || 'production'
      },
      treeshake: commandOptions.config.buildOptions.watch ? false : (_commandOptions$confi = commandOptions.config.installOptions.treeshake) !== null && _commandOptions$confi !== void 0 ? _commandOptions$confi : true
    }
  }); // Unlike dev (where we scan from source code) the built output guarantees that we
  // will can scan all used entrypoints. Set to `[]` to improve tree-shaking performance.

  installConfig.knownEntrypoints = []; // 1. Scan imports from your final built JS files.

  const installTargets = await getInstallTargets(installConfig, scannedFiles); // 2. Install dependencies, based on the scan of your final build.

  const installResult = await run(_objectSpread2(_objectSpread2({}, commandOptions), {}, {
    installTargets,
    config: installConfig
  }));
  return installResult;
}
/**
 * FileBuilder - This class is responsible for building a file. It is broken into
 * individual stages so that the entire application build process can be tackled
 * in stages (build -> resolve -> write to disk).
 */


class FileBuilder {
  constructor({
    filepath,
    outDir,
    config
  }) {
    this.output = {};
    this.filesToResolve = {};
    this.filesToProxy = [];
    this.filepath = filepath;
    this.outDir = outDir;
    this.config = config;
  }

  async buildFile(isExitOnBuild) {
    this.filesToResolve = {};
    const srcExt = path.extname(this.filepath);
    const builtFileOutput = await buildFile(this.filepath, {
      plugins: this.config.plugins,
      isDev: false,
      isExitOnBuild,
      isHmrEnabled: false,
      sourceMaps: this.config.buildOptions.sourceMaps
    });

    for (const [fileExt, buildResult] of Object.entries(builtFileOutput)) {
      let {
        code,
        map
      } = buildResult;

      if (!code) {
        continue;
      }

      const outFilename = replaceExt(path.basename(this.filepath), srcExt, fileExt);
      const outLoc = path.join(this.outDir, outFilename);
      const sourceMappingURL = outFilename + '.map';

      if (typeof code === 'string') {
        switch (fileExt) {
          case '.css':
            {
              if (map) code = cssSourceMappingURL(code, sourceMappingURL);
              this.filesToResolve[outLoc] = {
                baseExt: fileExt,
                expandedExt: fileExt,
                contents: code,
                locOnDisk: this.filepath
              };
              break;
            }

          case '.js':
            {
              if (builtFileOutput['.css']) {
                // inject CSS if imported directly
                const cssFilename = outFilename.replace(/\.js$/i, '.css');
                code = `import './${cssFilename}';\n` + code;
              }

              code = wrapImportMeta({
                code,
                env: true,
                hmr: false,
                config: this.config
              });
              if (map) code = jsSourceMappingURL(code, sourceMappingURL);
              this.filesToResolve[outLoc] = {
                baseExt: fileExt,
                expandedExt: fileExt,
                contents: code,
                locOnDisk: this.filepath
              };
              break;
            }

          case '.html':
            {
              code = wrapHtmlResponse({
                code,
                hmr: getIsHmrEnabled(this.config),
                isDev: false,
                config: this.config,
                mode: 'production'
              });
              this.filesToResolve[outLoc] = {
                baseExt: fileExt,
                expandedExt: fileExt,
                contents: code,
                locOnDisk: this.filepath
              };
              break;
            }
        }
      }

      this.output[outLoc] = code;

      if (map) {
        this.output[path.join(this.outDir, sourceMappingURL)] = map;
      }
    }
  }

  async resolveImports(importMap) {
    let isSuccess = true;
    this.filesToProxy = [];

    for (const [outLoc, rawFile] of Object.entries(this.filesToResolve)) {
      // don’t transform binary file contents
      if (Buffer.isBuffer(rawFile.contents)) {
        continue;
      }

      const file = rawFile;
      const resolveImportSpecifier = createImportResolver({
        fileLoc: file.locOnDisk,
        dependencyImportMap: importMap,
        config: this.config
      });
      const resolvedCode = await transformFileImports(file, spec => {
        // Try to resolve the specifier to a known URL in the project
        let resolvedImportUrl = resolveImportSpecifier(spec); // NOTE: If the import cannot be resolved, we'll need to re-install
        // your dependencies. We don't support this yet, but we will.
        // Until supported, just exit here.

        if (!resolvedImportUrl) {
          isSuccess = false;
          logger.error(`${file.locOnDisk} - Could not resolve unknown import "${spec}".`);
          return spec;
        } // Ignore "http://*" imports


        if (url.parse(resolvedImportUrl).protocol) {
          return spec;
        } // Handle normal "./" & "../" import specifiers


        const importExtName = path.extname(resolvedImportUrl);
        const isProxyImport = importExtName && (file.baseExt === '.js' || file.baseExt === '.html') && importExtName !== '.js';
        const isAbsoluteUrlPath = path.posix.isAbsolute(resolvedImportUrl);
        let resolvedImportPath = removeLeadingSlash(path.normalize(resolvedImportUrl)); // We treat ".proxy.js" files special: we need to make sure that they exist on disk
        // in the final build, so we mark them to be written to disk at the next step.

        if (isProxyImport) {
          if (isAbsoluteUrlPath) {
            this.filesToProxy.push(path.resolve(this.config.devOptions.out, resolvedImportPath));
          } else {
            this.filesToProxy.push(path.resolve(path.dirname(outLoc), resolvedImportPath));
          }
        }

        if (isProxyImport) {
          resolvedImportPath = resolvedImportPath + '.proxy.js';
          resolvedImportUrl = resolvedImportUrl + '.proxy.js';
        } // When dealing with an absolute import path, we need to honor the baseUrl


        if (isAbsoluteUrlPath) {
          resolvedImportUrl = relativeURL(path.dirname(outLoc), path.resolve(this.config.devOptions.out, resolvedImportPath));
        } // Make sure that a relative URL always starts with "./"


        if (!resolvedImportUrl.startsWith('.') && !resolvedImportUrl.startsWith('/')) {
          resolvedImportUrl = './' + resolvedImportUrl;
        }

        return resolvedImportUrl;
      });
      this.output[outLoc] = resolvedCode;
    }

    return isSuccess;
  }

  async writeToDisk() {
    mkdirp.sync(this.outDir);

    for (const [outLoc, code] of Object.entries(this.output)) {
      const encoding = typeof code === 'string' ? 'utf-8' : undefined;
      await fs.promises.writeFile(outLoc, code, encoding);
    }
  }

  async writeProxyToDisk(originalFileLoc) {
    const proxiedCode = this.output[originalFileLoc];
    const importProxyFileLoc = originalFileLoc + '.proxy.js';
    const proxiedUrl = originalFileLoc.substr(this.config.devOptions.out.length).replace(/\\/g, '/');
    const proxyCode = await wrapImportProxy({
      url: proxiedUrl,
      code: proxiedCode,
      hmr: false,
      config: this.config
    });
    await fs.promises.writeFile(importProxyFileLoc, proxyCode, 'utf-8');
  }

}

async function command$1(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  const buildDirectoryLoc = config.devOptions.out;
  const internalFilesBuildLoc = path.join(buildDirectoryLoc, config.buildOptions.metaDir);
  const mountedDirectories = Object.entries(config.mount).map(([fromDisk, toUrl]) => {
    return [path.resolve(cwd, fromDisk), path.resolve(buildDirectoryLoc, removeLeadingSlash(toUrl))];
  });

  if (config.buildOptions.clean) {
    rimraf.sync(buildDirectoryLoc);
  }

  mkdirp.sync(buildDirectoryLoc);
  mkdirp.sync(internalFilesBuildLoc);

  for (const runPlugin of config.plugins) {
    if (runPlugin.run) {
      await runPlugin.run({
        isDev: false,
        isHmrEnabled: false,
        // @ts-ignore: internal API only
        log: (msg, data = {}) => {
          if (msg === 'WORKER_MSG') {
            logger.info(`[${runPlugin.name}] ${data.msg.trim()}`);
          }
        }
      }).catch(err => {
        logger.error(err.toString(), {
          name: runPlugin.name
        });
        process.exit(1);
      });
    }
  } // Write the `import.meta.env` contents file to disk


  await fs.promises.writeFile(path.join(internalFilesBuildLoc, 'env.js'), generateEnvModule('production'));

  if (getIsHmrEnabled(config)) {
    await fs.promises.writeFile(path.resolve(internalFilesBuildLoc, 'hmr.js'), HMR_CLIENT_CODE);
    hmrEngine = new EsmHmrEngine();
  }

  logger.info(colors.yellow('! building source…'));
  const buildStart = perf_hooks.performance.now();
  const buildPipelineFiles = {};
  /** Install all needed dependencies, based on the master buildPipelineFiles list.  */

  async function installDependencies() {
    const scannedFiles = Object.values(buildPipelineFiles).map(f => Object.values(f.filesToResolve)).reduce((flat, item) => flat.concat(item), []);
    const installDest = path.join(buildDirectoryLoc, config.buildOptions.webModulesUrl);
    const installResult = await installOptimizedDependencies(scannedFiles, installDest, _objectSpread2({}, commandOptions));

    if (!installResult.success || installResult.hasError || !installResult.importMap) {
      process.exit(1);
    }

    const allFiles = glob.sync(`**/*`, {
      cwd: installDest,
      absolute: true,
      nodir: true,
      dot: true
    });

    for (const installedFileLoc of allFiles) {
      if (!installedFileLoc.endsWith('import-map.json') && path.extname(installedFileLoc) !== '.js') {
        const proxiedCode = await readFile(installedFileLoc);
        const importProxyFileLoc = installedFileLoc + '.proxy.js';
        const proxiedUrl = installedFileLoc.substr(buildDirectoryLoc.length).replace(/\\/g, '/');
        const proxyCode = await wrapImportProxy({
          url: proxiedUrl,
          code: proxiedCode,
          hmr: false,
          config: config
        });
        await fs.promises.writeFile(importProxyFileLoc, proxyCode, 'utf-8');
      }
    }

    return installResult;
  } // 0. Find all source files.


  for (const [fromDisk, dirDest] of mountedDirectories) {
    const allFiles = glob.sync(`**/*`, {
      ignore: config.exclude,
      cwd: fromDisk,
      absolute: true,
      nodir: true,
      dot: true
    });

    for (const rawLocOnDisk of allFiles) {
      const locOnDisk = path.resolve(rawLocOnDisk); // this is necessary since glob.sync() returns paths with / on windows.  path.resolve() will switch them to the native path separator.

      const finalDest = locOnDisk.replace(fromDisk, dirDest);
      const outDir = path.dirname(finalDest);
      const buildPipelineFile = new FileBuilder({
        filepath: locOnDisk,
        outDir,
        config
      });
      buildPipelineFiles[locOnDisk] = buildPipelineFile;
    }
  } // 1. Build all files for the first time, from source.


  const parallelWorkQueue = new PQueue({
    concurrency: CONCURRENT_WORKERS
  });
  const allBuildPipelineFiles = Object.values(buildPipelineFiles);

  for (const buildPipelineFile of allBuildPipelineFiles) {
    parallelWorkQueue.add(() => buildPipelineFile.buildFile(true));
  }

  await parallelWorkQueue.onIdle();
  const buildEnd = perf_hooks.performance.now();
  logger.info(`${colors.green('✔')} build complete ${colors.dim(`[${((buildEnd - buildStart) / 1000).toFixed(2)}s]`)}`); // 2. Install all dependencies. This gets us the import map we need to resolve imports.

  let installResult = await installDependencies(); // 3. Resolve all built file imports.

  for (const buildPipelineFile of allBuildPipelineFiles) {
    parallelWorkQueue.add(() => buildPipelineFile.resolveImports(installResult.importMap));
  }

  await parallelWorkQueue.onIdle(); // 4. Write files to disk.

  const allImportProxyFiles = new Set(allBuildPipelineFiles.map(b => b.filesToProxy).reduce((flat, item) => flat.concat(item), []));

  for (const buildPipelineFile of allBuildPipelineFiles) {
    parallelWorkQueue.add(() => buildPipelineFile.writeToDisk());

    for (const builtFile of Object.keys(buildPipelineFile.output)) {
      if (allImportProxyFiles.has(builtFile)) {
        parallelWorkQueue.add(() => buildPipelineFile.writeProxyToDisk(builtFile));
      }
    }
  }

  await parallelWorkQueue.onIdle(); // 5. Optimize the build.

  if (!config.buildOptions.watch) {
    await runPipelineCleanupStep(config);
    await runPipelineOptimizeStep(buildDirectoryLoc, {
      plugins: config.plugins,
      isDev: false,
      isExitOnBuild: false,
      isHmrEnabled: false,
      sourceMaps: config.buildOptions.sourceMaps
    });
    logger.info(`${colors.underline(colors.green(colors.bold('▶ Build Complete!')))}\n\n`);
    return;
  } // "--watch --hmr" mode - Tell users about the HMR WebSocket URL


  if (hmrEngine) {
    logger.info(`[HMR] WebSocket URL available at ${colors.cyan(`${hmrEngine.wsUrl}`)}`);
  } // "--watch" mode - Start watching the file system.
  // Defer "chokidar" loading to here, to reduce impact on overall startup time


  logger.info(colors.cyan('Watching for changes...'));
  const chokidar = await Promise.resolve().then(() => require('chokidar'));

  function onDeleteEvent(fileLoc) {
    delete buildPipelineFiles[fileLoc];
  }

  async function onWatchEvent(fileLoc) {
    logger.info(colors.cyan('File changed...'));
    const [fromDisk, dirDest] = mountedDirectories.find(([fromDisk]) => fileLoc.startsWith(fromDisk)) || [];

    if (!fromDisk || !dirDest) {
      return;
    }

    const finalDest = fileLoc.replace(fromDisk, dirDest);
    const outDir = path.dirname(finalDest);
    const changedPipelineFile = new FileBuilder({
      filepath: fileLoc,
      outDir,
      config
    });
    buildPipelineFiles[fileLoc] = changedPipelineFile; // 1. Build the file.

    await changedPipelineFile.buildFile(false).catch(err => {
      logger.error(err.message, {
        name: changedPipelineFile.filepath
      });
    }); // 2. Resolve any ESM imports. Handle new imports by triggering a re-install.

    let resolveSuccess = await changedPipelineFile.resolveImports(installResult.importMap);

    if (!resolveSuccess) {
      await installDependencies();
      resolveSuccess = await changedPipelineFile.resolveImports(installResult.importMap);

      if (!resolveSuccess) {
        logger.error('Exiting...');
        process.exit(1);
      }
    } // 3. Write to disk. If any proxy imports are needed, write those as well.


    await changedPipelineFile.writeToDisk();
    const allBuildPipelineFiles = Object.values(buildPipelineFiles);
    const allImportProxyFiles = new Set(allBuildPipelineFiles.map(b => b.filesToProxy).reduce((flat, item) => flat.concat(item), []));

    for (const builtFile of Object.keys(changedPipelineFile.output)) {
      if (allImportProxyFiles.has(builtFile)) {
        await changedPipelineFile.writeProxyToDisk(builtFile);
      }
    }

    if (hmrEngine) {
      hmrEngine.broadcastMessage({
        type: 'reload'
      });
    }
  }

  const watcher = chokidar.watch(mountedDirectories.map(([dirDisk]) => dirDisk), {
    ignored: config.exclude,
    ignoreInitial: true,
    persistent: true,
    disableGlobbing: false
  });
  watcher.on('add', fileLoc => onWatchEvent(fileLoc));
  watcher.on('change', fileLoc => onWatchEvent(fileLoc));
  watcher.on('unlink', fileLoc => onDeleteEvent(fileLoc)); // We intentionally never want to exit in watch mode!

  return new Promise(() => {});
}

const cwd$2 = process.cwd();
const paintEvent = {
  BUILD_FILE: 'BUILD_FILE',
  LOAD_ERROR: 'LOAD_ERROR',
  SERVER_RESPONSE: 'SERVER_RESPONSE',
  SERVER_START: 'SERVER_START',
  WORKER_COMPLETE: 'WORKER_COMPLETE',
  WORKER_MSG: 'WORKER_MSG',
  WORKER_RESET: 'WORKER_RESET',
  WORKER_UPDATE: 'WORKER_UPDATE'
};
/**
 * Get the actual port, based on the `defaultPort`.
 * If the default port was not available, then we'll prompt the user if its okay
 * to use the next available port.
 */

async function getPort(defaultPort) {
  const bestAvailablePort = await detectPort(defaultPort);

  if (defaultPort !== bestAvailablePort) {
    let useNextPort = false;

    if (process.stdout.isTTY) {
      const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
      });
      useNextPort = await new Promise(resolve => {
        rl.question(colors.yellow(`! Port ${colors.bold(defaultPort)} not available. Run on port ${colors.bold(bestAvailablePort)} instead? (Y/n) `), answer => {
          resolve(!/^no?$/i.test(answer));
        });
      });
      rl.close();
    }

    if (!useNextPort) {
      logger.error(`✘ Port ${colors.bold(defaultPort)} not available. Use ${colors.bold('--port')} to specify a different port.`);
      process.exit(1);
    }
  }

  return bestAvailablePort;
}
const WORKER_BASE_STATE = {
  done: false,
  error: null,
  state: null,
  output: ''
};
function paint(bus, plugins) {
  let port;
  let hostname;
  let protocol = '';
  let startTimeMs;
  let ips = [];
  const allWorkerStates = {};
  const allFileBuilds = new Set();

  for (const plugin of plugins) {
    allWorkerStates[plugin] = _objectSpread2({}, WORKER_BASE_STATE);
  }

  function setupWorker(id) {
    if (!allWorkerStates[id]) {
      allWorkerStates[id] = _objectSpread2({}, WORKER_BASE_STATE);
    }
  }

  function repaint() {
    // Clear Page
    process.stdout.write(process.platform === 'win32' ? '\x1B[2J\x1B[0f' : '\x1B[2J\x1B[3J\x1B[H'); // Header

    process.stdout.write(`${colors.bold(`snowpack`)}\n\n`); // Server Stats

    const isServerStarted = startTimeMs > 0 && port > 0 && protocol;

    if (isServerStarted) {
      process.stdout.write(`  ${colors.bold(colors.cyan(`${protocol}//${hostname}:${port}`))}`);

      for (const ip of ips) {
        process.stdout.write(`${colors.cyan(` • `)}${colors.bold(colors.cyan(`${protocol}//${ip}:${port}`))}`);
      }

      process.stdout.write('\n');
      process.stdout.write(colors.dim(startTimeMs < 1000 ? `  Server started in ${startTimeMs}ms.` : `  Server started.`));

      if (allFileBuilds.size > 0) {
        process.stdout.write(colors.dim(` Building...`));
      }

      process.stdout.write('\n\n');
    } else {
      process.stdout.write(colors.dim(`  Server starting…`) + '\n\n');
    } // Console Output


    const history = logger.getHistory();

    if (history.length) {
      process.stdout.write(`${colors.underline(colors.bold('▼ Console'))}\n\n`);
      process.stdout.write(history.join('\n'));
      process.stdout.write('\n\n');
    } // Worker Dashboards


    for (const [script, workerState] of Object.entries(allWorkerStates)) {
      if (!workerState.output) {
        continue;
      }

      const colorsFn = Array.isArray(workerState.error) ? colors.red : colors.reset;
      process.stdout.write(`${colorsFn(colors.underline(colors.bold('▼ ' + script)))}\n\n`);
      process.stdout.write('  ' + workerState.output.trim().replace(/\n/gm, '\n  '));
      process.stdout.write('\n\n');
    }
  }

  bus.on(paintEvent.BUILD_FILE, ({
    id,
    isBuilding
  }) => {
    if (isBuilding) {
      allFileBuilds.add(path.relative(cwd$2, id));
    } else {
      allFileBuilds.delete(path.relative(cwd$2, id));
    }

    repaint();
  });
  bus.on(paintEvent.WORKER_MSG, ({
    id,
    msg
  }) => {
    setupWorker(id);
    allWorkerStates[id].output += msg;
    repaint();
  });
  bus.on(paintEvent.WORKER_UPDATE, ({
    id,
    state
  }) => {
    if (typeof state !== undefined) {
      setupWorker(id);
      allWorkerStates[id].state = state;
    }

    repaint();
  });
  bus.on(paintEvent.WORKER_COMPLETE, ({
    id,
    error
  }) => {
    allWorkerStates[id].state = ['DONE', 'green'];
    allWorkerStates[id].done = true;
    allWorkerStates[id].error = allWorkerStates[id].error || error;
    repaint();
  });
  bus.on(paintEvent.WORKER_RESET, ({
    id
  }) => {
    allWorkerStates[id] = _objectSpread2({}, WORKER_BASE_STATE);
    repaint();
  });
  bus.on(paintEvent.SERVER_START, info => {
    startTimeMs = info.startTimeMs;
    hostname = info.hostname;
    port = info.port;
    protocol = info.protocol;
    ips = info.ips;
    repaint();
  }); // replace logging behavior with repaint (note: messages are retrieved later, with logger.getHistory())

  logger.on('debug', () => {
    repaint();
  });
  logger.on('info', () => {
    repaint();
  });
  logger.on('warn', () => {
    repaint();
  });
  logger.on('error', () => {
    repaint();
  });
  repaint();
}

const DEFAULT_PROXY_ERROR_HANDLER = (err, req, res) => {
  const reqUrl = req.url;
  logger.error(`✘ ${reqUrl}\n${err.message}`);
  sendError(req, res, 502);
};

function shouldProxy(pathPrefix, req) {
  const reqPath = decodeURI(url.parse(req.url).pathname);
  return reqPath.startsWith(pathPrefix);
}

const sendFile = (req, res, body, fileLoc, ext = '.html') => {
  var _req$headers$cacheCo;

  body = Buffer.from(body);
  const ETag = etag(body, {
    weak: true
  });
  const contentType = mime.contentType(ext);
  const headers = {
    'Accept-Ranges': 'bytes',
    'Access-Control-Allow-Origin': '*',
    'Content-Type': contentType || 'application/octet-stream',
    ETag,
    Vary: 'Accept-Encoding'
  };

  if (req.headers['if-none-match'] === ETag) {
    res.writeHead(304, headers);
    res.end();
    return;
  }

  let acceptEncoding = req.headers['accept-encoding'] || '';

  if (((_req$headers$cacheCo = req.headers['cache-control']) === null || _req$headers$cacheCo === void 0 ? void 0 : _req$headers$cacheCo.includes('no-transform')) || ['HEAD', 'OPTIONS'].includes(req.method) || !contentType || !isCompressible(contentType)) {
    acceptEncoding = '';
  } // Handle gzip compression


  if (/\bgzip\b/.test(acceptEncoding) && stream.Readable.from) {
    const bodyStream = stream.Readable.from([body]);
    headers['Content-Encoding'] = 'gzip';
    res.writeHead(200, headers);
    stream.pipeline(bodyStream, zlib.createGzip(), res, function onError(err) {
      if (err) {
        res.end();
        logger.error(`✘ An error occurred serving ${colors.bold(req.url)}`);
        logger.error(typeof err !== 'string' ? err.toString() : err);
      }
    });
    return;
  } // Handle partial requests


  const {
    range
  } = req.headers;

  if (range) {
    const {
      size: fileSize
    } = fs.statSync(fileLoc);
    const [rangeStart, rangeEnd] = range.replace(/bytes=/, '').split('-');
    const start = parseInt(rangeStart, 10);
    const end = rangeEnd ? parseInt(rangeEnd, 10) : fileSize - 1;
    const chunkSize = end - start + 1;
    const fileStream = fs.createReadStream(fileLoc, {
      start,
      end
    });
    res.writeHead(206, _objectSpread2(_objectSpread2({}, headers), {}, {
      'Content-Range': `bytes ${start}-${end}/${fileSize}`,
      'Content-Length': chunkSize
    }));
    fileStream.pipe(res);
    return;
  }

  res.writeHead(200, headers);
  res.write(body);
  res.end();
};

const sendError = (req, res, status) => {
  const contentType = mime.contentType(path.extname(req.url) || '.html');
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Accept-Ranges': 'bytes',
    'Content-Type': contentType || 'application/octet-stream',
    Vary: 'Accept-Encoding'
  };
  res.writeHead(status, headers);
  res.end();
};

function getUrlFromFile(mountedDirectories, fileLoc, config) {
  for (const [dirDisk, dirUrl] of mountedDirectories) {
    if (fileLoc.startsWith(dirDisk + path.sep)) {
      const {
        baseExt
      } = getExt(fileLoc);
      const resolvedDirUrl = dirUrl === '/' ? '' : dirUrl;
      return replaceExt(fileLoc.replace(dirDisk, resolvedDirUrl).replace(/[/\\]+/g, '/'), baseExt, config._extensionMap[baseExt] || srcFileExtensionMapping[baseExt] || baseExt);
    }
  }

  return null;
}

async function command$2(commandOptions) {
  const {
    cwd,
    config
  } = commandOptions;
  const {
    port: defaultPort,
    hostname,
    open
  } = config.devOptions;
  const isHmr = typeof config.devOptions.hmr !== 'undefined' ? config.devOptions.hmr : true; // Start the startup timer!

  let serverStart = perf_hooks.performance.now();
  const port = await getPort(defaultPort); // Reset the clock if we had to wait for the user to select a new port.

  if (port !== defaultPort) {
    serverStart = perf_hooks.performance.now();
  }

  const messageBus = new events.EventEmitter(); // note: this would cause an infinite loop if not for the logger.on(…) in `paint.ts`.

  console.log = (...args) => {
    logger.info(util.format(...args));
  };

  console.warn = (...args) => {
    logger.warn(util.format(...args));
  };

  console.error = (...args) => {
    logger.error(util.format(...args));
  };

  paint(messageBus, config.plugins.map(p => p.name));
  const inMemoryBuildCache = new Map();
  const filesBeingDeleted = new Set();
  const filesBeingBuilt = new Map();
  const mountedDirectories = Object.entries(config.mount).map(([fromDisk, toUrl]) => {
    return [path.resolve(cwd, fromDisk), toUrl];
  }); // Set the proper install options, in case an install is needed.

  const dependencyImportMapLoc = path.join(DEV_DEPENDENCIES_DIR, 'import-map.json');
  logger.debug(`Using cache folder: ${path.relative(cwd, DEV_DEPENDENCIES_DIR)}`);
  const installCommandOptions = merge__default(commandOptions, {
    config: {
      installOptions: {
        dest: DEV_DEPENDENCIES_DIR,
        env: {
          NODE_ENV: process.env.NODE_ENV || 'development'
        },
        treeshake: false
      }
    }
  }); // Start with a fresh install of your dependencies, if needed.

  if (!(await checkLockfileHash(DEV_DEPENDENCIES_DIR)) || !fs.existsSync(dependencyImportMapLoc)) {
    logger.debug('Cache out of date or missing. Updating…');
    logger.info(colors.yellow('! updating dependencies...'));
    await command(installCommandOptions);
    await updateLockfileHash(DEV_DEPENDENCIES_DIR);
  } else {
    logger.debug(`Cache up-to-date. Using existing cache`);
  }

  let dependencyImportMap = {
    imports: {}
  };

  try {
    dependencyImportMap = JSON.parse(await fs.promises.readFile(dependencyImportMapLoc, {
      encoding: 'utf-8'
    }));
  } catch (err) {// no import-map found, safe to ignore
  }

  const devProxies = {};
  config.proxy.forEach(([pathPrefix, proxyOptions]) => {
    const proxyServer = devProxies[pathPrefix] = HttpProxy.createProxyServer(proxyOptions);

    for (const [onEventName, eventHandler] of Object.entries(proxyOptions.on)) {
      proxyServer.on(onEventName, eventHandler);
    }

    if (!proxyOptions.on.error) {
      proxyServer.on('error', DEFAULT_PROXY_ERROR_HANDLER);
    }

    logger.info(`Proxy created: ${pathPrefix} -> ${proxyOptions.target || proxyOptions.forward}`);
  });

  const readCredentials = async cwd => {
    const [cert, key] = await Promise.all([fs.promises.readFile(path.join(cwd, 'snowpack.crt')), fs.promises.readFile(path.join(cwd, 'snowpack.key'))]);
    return {
      cert,
      key
    };
  };

  let credentials;

  if (config.devOptions.secure) {
    try {
      credentials = await readCredentials(cwd);
    } catch (e) {
      logger.error(`✘ No HTTPS credentials found! Missing Files:  ${colors.bold('snowpack.crt')}, ${colors.bold('snowpack.key')}`);
      logger.info(`You can automatically generate credentials for your project via either:

  - ${colors.cyan('devcert')}: ${colors.yellow('npx devcert-cli generate localhost')}
    https://github.com/davewasmer/devcert-cli (no install required)

  - ${colors.cyan('mkcert')}: ${colors.yellow('mkcert -install && mkcert -key-file snowpack.key -cert-file snowpack.crt localhost')}

    https://github.com/FiloSottile/mkcert (install required)`);
      process.exit(1);
    }
  }

  for (const runPlugin of config.plugins) {
    if (runPlugin.run) {
      runPlugin.run({
        isDev: true,
        isHmrEnabled: isHmr,
        // @ts-ignore: internal API only
        log: (msg, data) => {
          messageBus.emit(msg, _objectSpread2(_objectSpread2({}, data), {}, {
            id: runPlugin.name
          }));
        }
      }).then(() => {
        logger.info('Command completed.', {
          name: runPlugin.name
        });
      }).catch(err => {
        logger.error(`Command exited with error code: ${err}`, {
          name: runPlugin.name
        });
        process.exit(1);
      });
    }
  }

  async function requestHandler(req, res) {
    const reqUrl = req.url;
    const reqUrlHmrParam = reqUrl.includes('?mtime=') && reqUrl.split('?')[1];
    let reqPath = decodeURI(url.parse(reqUrl).pathname);
    const originalReqPath = reqPath;
    let isProxyModule = false;
    let isSourceMap = false;

    if (reqPath.endsWith('.proxy.js')) {
      isProxyModule = true;
      reqPath = replaceExt(reqPath, '.proxy.js', '');
    } else if (reqPath.endsWith('.map')) {
      isSourceMap = true;
      reqPath = replaceExt(reqPath, '.map', '');
    }

    res.on('finish', () => {
      const {
        method,
        url
      } = req;
      const {
        statusCode
      } = res;

      if (statusCode !== 200) {
        messageBus.emit(paintEvent.SERVER_RESPONSE, {
          method,
          url,
          statusCode
        });
      }
    });

    if (reqPath === getMetaUrlPath('/hmr.js', config)) {
      sendFile(req, res, HMR_CLIENT_CODE, reqPath, '.js');
      return;
    }

    if (reqPath === getMetaUrlPath('/env.js', config)) {
      sendFile(req, res, generateEnvModule('development'), reqPath, '.js');
      return;
    }

    for (const [pathPrefix] of config.proxy) {
      if (!shouldProxy(pathPrefix, req)) {
        continue;
      }

      devProxies[pathPrefix].web(req, res);
      return;
    }

    const attemptedFileLoads = [];

    function attemptLoadFile(requestedFile) {
      if (attemptedFileLoads.includes(requestedFile)) {
        return Promise.resolve(null);
      }

      attemptedFileLoads.push(requestedFile);
      return fs.promises.stat(requestedFile).then(stat => stat.isFile() ? requestedFile : null).catch(() => null
      /* ignore */
      );
    }

    let requestedFile = path.parse(reqPath);
    let requestedFileExt = requestedFile.ext.toLowerCase();
    let responseFileExt = requestedFileExt;
    let isRoute = !requestedFileExt || requestedFileExt === '.html'; // Now that we've set isRoute properly, give `requestedFileExt` a fallback

    requestedFileExt = requestedFileExt || '.html';

    async function getFileFromUrl(reqPath) {
      if (reqPath.startsWith(config.buildOptions.webModulesUrl)) {
        const fileLoc = await attemptLoadFile(reqPath.replace(config.buildOptions.webModulesUrl, DEV_DEPENDENCIES_DIR));

        if (fileLoc) {
          return fileLoc;
        }
      }

      for (const [dirDisk, dirUrl] of mountedDirectories) {
        let requestedFile;

        if (dirUrl === '/') {
          requestedFile = path.join(dirDisk, reqPath);
        } else if (reqPath.startsWith(dirUrl)) {
          requestedFile = path.join(dirDisk, reqPath.replace(dirUrl, './'));
        } else {
          continue;
        }

        if (isRoute) {
          let fileLoc = (await attemptLoadFile(requestedFile)) || (await attemptLoadFile(requestedFile + '.html')) || (await attemptLoadFile(requestedFile + 'index.html')) || (await attemptLoadFile(requestedFile + '/index.html'));

          if (!fileLoc && dirUrl === '/' && config.devOptions.fallback) {
            const fallbackFile = path.join(dirDisk, config.devOptions.fallback);
            fileLoc = await attemptLoadFile(fallbackFile);
          }

          if (fileLoc) {
            responseFileExt = '.html';
            return fileLoc;
          }
        } else {
          for (const potentialSourceFile of getInputsFromOutput(requestedFile, config.plugins)) {
            const fileLoc = await attemptLoadFile(potentialSourceFile);

            if (fileLoc) {
              return fileLoc;
            }
          }
        }
      }

      return null;
    }

    const fileLoc = await getFileFromUrl(reqPath);

    if (!fileLoc) {
      const prefix = colors.red('  ✘ ');
      logger.error(`[404] ${reqUrl}\n${attemptedFileLoads.map(loc => prefix + loc).join('\n')}`);
      return sendError(req, res, 404);
    }
    /**
     * Given a file, build it. Building a file sends it through our internal file builder
     * pipeline, and outputs a build map representing the final build. A Build Map is used
     * because one source file can result in multiple built files (Example: .svelte -> .js & .css).
     */


    async function buildFile$1(fileLoc) {
      const existingBuilderPromise = filesBeingBuilt.get(fileLoc);

      if (existingBuilderPromise) {
        return existingBuilderPromise;
      }

      const fileBuilderPromise = (async () => {
        const builtFileOutput = await buildFile(fileLoc, {
          plugins: config.plugins,
          isDev: true,
          isExitOnBuild: false,
          isHmrEnabled: isHmr,
          sourceMaps: config.buildOptions.sourceMaps
        });
        inMemoryBuildCache.set(fileLoc, builtFileOutput);
        return builtFileOutput;
      })();

      filesBeingBuilt.set(fileLoc, fileBuilderPromise);

      try {
        messageBus.emit(paintEvent.BUILD_FILE, {
          id: fileLoc,
          isBuilding: true
        });
        return await fileBuilderPromise;
      } finally {
        filesBeingBuilt.delete(fileLoc);
        messageBus.emit(paintEvent.BUILD_FILE, {
          id: fileLoc,
          isBuilding: false
        });
      }
    }
    /**
     * Wrap Response: The same build result can be expressed in different ways based on
     * the URL. For example, "App.css" should return CSS but "App.css.proxy.js" should
     * return a JS representation of that CSS. This is handled in the wrap step.
     */


    async function wrapResponse(code, {
      hasCssResource,
      sourceMap,
      sourceMappingURL
    }) {
      // transform special requests
      if (isRoute) {
        code = wrapHtmlResponse({
          code: code,
          hmr: isHmr,
          isDev: true,
          config,
          mode: 'development'
        });
      } else if (isProxyModule) {
        responseFileExt = '.js';
      } else if (isSourceMap && sourceMap) {
        responseFileExt = '.map';
        code = sourceMap;
      } // transform other files


      switch (responseFileExt) {
        case '.css':
          {
            if (sourceMap) code = cssSourceMappingURL(code, sourceMappingURL);
            break;
          }

        case '.js':
          {
            if (isProxyModule) {
              code = await wrapImportProxy({
                url: reqPath,
                code,
                hmr: isHmr,
                config
              });
            } else {
              code = wrapImportMeta({
                code: code,
                env: true,
                hmr: isHmr,
                config
              });
            }

            if (hasCssResource) code = `import './${path.basename(reqPath).replace(/.js$/, '.css.proxy.js')}';\n` + code; // source mapping

            if (sourceMap) code = jsSourceMappingURL(code, sourceMappingURL);
            break;
          }
      } // by default, return file from disk


      return code;
    }
    /**
     * Resolve Imports: Resolved imports are based on the state of the file system, so
     * they can't be cached long-term with the build.
     */


    async function resolveResponseImports(fileLoc, responseExt, wrappedResponse) {
      const resolveImportSpecifier = createImportResolver({
        fileLoc,
        dependencyImportMap,
        config
      });
      wrappedResponse = await transformFileImports({
        locOnDisk: fileLoc,
        contents: wrappedResponse,
        baseExt: responseExt,
        expandedExt: getExt(fileLoc).expandedExt
      }, spec => {
        // Try to resolve the specifier to a known URL in the project
        const resolvedImportUrl = resolveImportSpecifier(spec);

        if (resolvedImportUrl) {
          // Ignore "http://*" imports
          if (url.parse(resolvedImportUrl).protocol) {
            return resolvedImportUrl;
          } // Support proxy file imports


          const extName = path.extname(resolvedImportUrl);

          if (extName && (responseExt === '.js' || responseExt === '.html') && extName !== '.js') {
            return resolvedImportUrl + '.proxy.js';
          }

          return resolvedImportUrl;
        }

        logger.error(`Import "${spec}" could not be resolved.
If this is a new package, re-run Snowpack with the ${colors.bold('--reload')} flag to rebuild.
If Snowpack is having trouble detecting the import, add ${colors.bold(`"install": ["${spec}"]`)} to your Snowpack config file.`);
        return spec;
      });
      let code = wrappedResponse;
      if (responseFileExt === '.js' && reqUrlHmrParam) code = await transformEsmImports(code, imp => {
        const importUrl = path.posix.resolve(path.posix.dirname(reqPath), imp);
        const node = hmrEngine.getEntry(importUrl);

        if (node && node.needsReplacement) {
          hmrEngine.markEntryForReplacement(node, false);
          return `${imp}?${reqUrlHmrParam}`;
        }

        return imp;
      });

      if (responseFileExt === '.js') {
        const isHmrEnabled = code.includes('import.meta.hot');
        const rawImports = await scanCodeImportsExports(code);
        const resolvedImports = rawImports.map(imp => {
          let spec = code.substring(imp.s, imp.e);

          if (imp.d > -1) {
            spec = matchDynamicImportValue(spec) || '';
          }

          spec = spec.replace(/\?mtime=[0-9]+$/, '');
          return path.posix.resolve(path.posix.dirname(reqPath), spec);
        });
        hmrEngine.setEntry(originalReqPath, resolvedImports, isHmrEnabled);
      }

      wrappedResponse = code;
      return wrappedResponse;
    }
    /**
     * Given a build, finalize it for the response. This involves running individual steps
     * needed to go from build result to sever response, including:
     *   - wrapResponse(): Wrap responses
     *   - resolveResponseImports(): Resolve all ESM imports
     */


    async function finalizeResponse(fileLoc, requestedFileExt, output) {
      // Verify that the requested file exists in the build output map.
      if (!output[requestedFileExt] || !Object.keys(output)) {
        return null;
      }

      const {
        code,
        map
      } = output[requestedFileExt];
      let finalResponse = code; // Wrap the response.

      const hasAttachedCss = requestedFileExt === '.js' && !!output['.css'];
      finalResponse = await wrapResponse(finalResponse, {
        hasCssResource: hasAttachedCss,
        sourceMap: map,
        sourceMappingURL: path.basename(requestedFile.base) + '.map'
      }); // Resolve imports.

      if (requestedFileExt === '.js' || requestedFileExt === '.html' || requestedFileExt === '.css') {
        finalResponse = await resolveResponseImports(fileLoc, requestedFileExt, finalResponse);
      } // Return the finalized response.


      return finalResponse;
    } // 1. Check the hot build cache. If it's already found, then just serve it.


    let hotCachedResponse = inMemoryBuildCache.get(fileLoc);

    if (hotCachedResponse) {
      const responseContent = await finalizeResponse(fileLoc, requestedFileExt, hotCachedResponse);

      if (!responseContent) {
        sendError(req, res, 404);
        return;
      }

      sendFile(req, res, responseContent, fileLoc, responseFileExt);
      return;
    } // 2. Load the file from disk. We'll need it to check the cold cache or build from scratch.


    const fileContents = await readFile(fileLoc); // 3. Send dependencies directly, since they were already build & resolved at install time.

    if (reqPath.startsWith(config.buildOptions.webModulesUrl) && !isProxyModule) {
      sendFile(req, res, fileContents, fileLoc, responseFileExt);
      return;
    } // 4. Check the persistent cache. If found, serve it via a "trust-but-verify" strategy.
    // Build it after sending, and if it no longer matches then assume the entire cache is suspect.
    // In that case, clear the persistent cache and then force a live-reload of the page.


    const cachedBuildData = !filesBeingDeleted.has(fileLoc) && (await cacache.get(BUILD_CACHE, fileLoc).catch(() => null));

    if (cachedBuildData) {
      const {
        originalFileHash
      } = cachedBuildData.metadata;
      const newFileHash = etag(fileContents);

      if (originalFileHash === newFileHash) {
        // IF THIS FAILS TS CHECK: If you are changing the structure of SnowpackBuildMap, be sure to
        // also update `BUILD_CACHE` in util.ts to a new unique name, to guarantee a clean cache for
        // our users.
        const coldCachedResponse = JSON.parse(cachedBuildData.data.toString());
        inMemoryBuildCache.set(fileLoc, coldCachedResponse); // Trust...

        const wrappedResponse = await finalizeResponse(fileLoc, requestedFileExt, coldCachedResponse);

        if (!wrappedResponse) {
          sendError(req, res, 404);
          return;
        }

        sendFile(req, res, wrappedResponse, fileLoc, responseFileExt); // ...but verify.

        let checkFinalBuildResult = null;

        try {
          checkFinalBuildResult = await buildFile$1(fileLoc);
        } catch (err) {// safe to ignore, it will be surfaced later anyway
        } finally {
          if (!checkFinalBuildResult || !cachedBuildData.data.equals(Buffer.from(JSON.stringify(checkFinalBuildResult)))) {
            inMemoryBuildCache.clear();
            await cacache.rm.all(BUILD_CACHE);
            hmrEngine.broadcastMessage({
              type: 'reload'
            });
          }
        }

        return;
      }
    } // 5. Final option: build the file, serve it, and cache it.


    let responseContent;
    let responseOutput;

    try {
      responseOutput = await buildFile$1(fileLoc);
    } catch (err) {
      logger.error(`${reqPath}
${err}`);
      sendError(req, res, 500);
      return;
    }

    try {
      responseContent = await finalizeResponse(fileLoc, requestedFileExt, responseOutput);
    } catch (err) {
      logger.error(`${reqPath}
${err}`);
      sendError(req, res, 500);
      return;
    }

    if (!responseContent) {
      sendError(req, res, 404);
      return;
    }

    sendFile(req, res, responseContent, fileLoc, responseFileExt);
    const originalFileHash = etag(fileContents);
    cacache.put(BUILD_CACHE, fileLoc, Buffer.from(JSON.stringify(responseOutput)), {
      metadata: {
        originalFileHash
      }
    });
  }

  const createServer = requestHandler => {
    if (credentials && config.proxy.length === 0) {
      return http2.createSecureServer(_objectSpread2(_objectSpread2({}, credentials), {}, {
        allowHTTP1: true
      }), requestHandler);
    } else if (credentials) {
      return https.createServer(credentials, requestHandler);
    }

    return http.createServer(requestHandler);
  };

  const server = createServer(async (req, res) => {
    try {
      return await requestHandler(req, res);
    } catch (err) {
      logger.error(`[500] ${req.url}`);
      logger.error(err.toString() || err);
      return sendError(req, res, 500);
    }
  }).on('error', err => {
    logger.error(colors.red(`  ✘ Failed to start server at port ${colors.bold(port)}.`), err);
    server.close();
    process.exit(1);
  }).on('upgrade', (req, socket, head) => {
    config.proxy.forEach(([pathPrefix, proxyOptions]) => {
      var _proxyOptions$target;

      const isWebSocket = proxyOptions.ws || ((_proxyOptions$target = proxyOptions.target) === null || _proxyOptions$target === void 0 ? void 0 : _proxyOptions$target.toString().startsWith('ws'));

      if (isWebSocket && shouldProxy(pathPrefix, req)) {
        devProxies[pathPrefix].ws(req, socket, head);
        logger.info('Upgrading to WebSocket');
      }
    });
  }).listen(port);
  const hmrEngine = new EsmHmrEngine({
    server
  });
  onProcessExit(() => {
    hmrEngine.disconnectAllClients();
  }); // Live Reload + File System Watching

  function updateOrBubble(url, visited) {
    if (visited.has(url)) {
      return;
    }

    visited.add(url);
    const node = hmrEngine.getEntry(url);

    if (node && node.isHmrEnabled) {
      hmrEngine.broadcastMessage({
        type: 'update',
        url
      });
    }

    if (node && node.isHmrAccepted) ; else if (node && node.dependents.size > 0) {
      node.dependents.forEach(dep => {
        hmrEngine.markEntryForReplacement(node, true);
        updateOrBubble(dep, visited);
      });
    } else {
      // We've reached the top, trigger a full page refresh
      hmrEngine.broadcastMessage({
        type: 'reload'
      });
    }
  }

  function handleHmrUpdate(fileLoc) {

    let updateUrl = getUrlFromFile(mountedDirectories, fileLoc, config);

    if (!updateUrl) {
      return;
    } // Append ".proxy.js" to Non-JS files to match their registered URL in the client app.


    if (!updateUrl.endsWith('.js')) {
      updateUrl += '.proxy.js';
    } // Check if a virtual file exists in the resource cache (ex: CSS from a Svelte file)
    // If it does, mark it for HMR replacement but DONT trigger a separate HMR update event.
    // This is because a virtual resource doesn't actually exist on disk, so we need the main
    // resource (the JS) to load first. Only after that happens will the CSS exist.


    const virtualCssFileUrl = updateUrl.replace(/.js$/, '.css');
    const virtualNode = hmrEngine.getEntry(`${virtualCssFileUrl}.proxy.js`);

    if (virtualNode) {
      hmrEngine.markEntryForReplacement(virtualNode, true);
    } // If the changed file exists on the page, trigger a new HMR update.


    if (hmrEngine.getEntry(updateUrl)) {
      updateOrBubble(updateUrl, new Set());
      return;
    } // Otherwise, reload the page if the file exists in our hot cache (which means that the
    // file likely exists on the current page, but is not supported by HMR (HTML, image, etc)).


    if (inMemoryBuildCache.has(fileLoc)) {
      hmrEngine.broadcastMessage({
        type: 'reload'
      });
      return;
    }
  } // Announce server has started


  const ips = Object.values(os.networkInterfaces()).reduce((every, i) => [...every, ...(i || [])], []).filter(i => i.family === 'IPv4' && i.internal === false).map(i => i.address);
  const protocol = config.devOptions.secure ? 'https:' : 'http:';
  messageBus.emit(paintEvent.SERVER_START, {
    protocol,
    hostname,
    port,
    ips,
    startTimeMs: Math.round(perf_hooks.performance.now() - serverStart)
  }); // Open the user's browser

  if (open !== 'none') {
    await openInBrowser(protocol, hostname, port, open);
  } // Start watching the file system.
  // Defer "chokidar" loading to here, to reduce impact on overall startup time


  const chokidar = await Promise.resolve().then(() => require('chokidar')); // Watch src files

  async function onWatchEvent(fileLoc) {
    logger.info(colors.cyan('File changed...'));
    handleHmrUpdate(fileLoc);
    inMemoryBuildCache.delete(fileLoc);
    filesBeingDeleted.add(fileLoc);
    await cacache.rm.entry(BUILD_CACHE, fileLoc);
    filesBeingDeleted.delete(fileLoc);
  }

  const watcher = chokidar.watch(mountedDirectories.map(([dirDisk]) => dirDisk), {
    ignored: config.exclude,
    persistent: true,
    ignoreInitial: true,
    disableGlobbing: false
  });
  watcher.on('add', fileLoc => onWatchEvent(fileLoc));
  watcher.on('change', fileLoc => onWatchEvent(fileLoc));
  watcher.on('unlink', fileLoc => onWatchEvent(fileLoc)); // Watch node_modules & rerun snowpack install if symlinked dep updates

  const symlinkedFileLocs = new Set(Object.keys(dependencyImportMap.imports).map(specifier => {
    const [packageName] = parsePackageImportSpecifier(specifier);
    return resolveDependencyManifest(packageName, cwd);
  }) // resolve symlink src location
  .filter(([_, packageManifest]) => packageManifest && !packageManifest['_id']) // only watch symlinked deps for now
  .map(([fileLoc]) => `${path.dirname(fileLoc)}/**`));

  function onDepWatchEvent() {
    hmrEngine.broadcastMessage({
      type: 'reload'
    });
  }

  const depWatcher = chokidar.watch([...symlinkedFileLocs], {
    cwd: '/',
    persistent: true,
    ignoreInitial: true,
    disableGlobbing: false
  });
  depWatcher.on('add', onDepWatchEvent);
  depWatcher.on('change', onDepWatchEvent);
  depWatcher.on('unlink', onDepWatchEvent);
  return new Promise(() => {});
}

const cwd$3 = process.cwd();

function printHelp() {
  logger.info(`
${colors.bold(`snowpack`)} - A faster build system for the modern web.

  Snowpack is best configured via config file.
  But, most configuration can also be passed via CLI flags.
  📖 ${colors.dim('https://www.snowpack.dev/#configuration')}

${colors.bold('Commands:')}
  snowpack dev          Develop your app locally.
  snowpack build        Build your app for production.
  snowpack install      (Advanced) Install web-ready dependencies.

${colors.bold('Flags:')}
  --config [path]       Set the location of your project config file.
  --help                Show this help message.
  --version             Show the current version.
  --reload              Clear Snowpack's local cache (troubleshooting).
  --verbose             View debug info (where available)
  --quiet               Don’t output anything (dev server will still log minimally)
    `.trim());
}

async function cli(args) {
  // parse CLI flags
  const cliFlags = yargs(args, {
    array: ['install', 'env', 'exclude', 'externalPackage']
  });

  if (cliFlags.verbose) {
    logger.level = 'debug';
  }

  if (cliFlags.quiet) {
    logger.level = 'silent';
  }

  if (cliFlags.help) {
    printHelp();
    process.exit(0);
  }

  if (cliFlags.version) {
    logger.info(require('../package.json').version);
    process.exit(0);
  }

  if (cliFlags.reload) {
    logger.info(colors.yellow('! clearing cache...'));
    await clearCache();
  } // Load the current package manifest


  let pkgManifest;

  try {
    pkgManifest = require(path.join(cwd$3, 'package.json'));
  } catch (err) {
    logger.error(`package.json not found in directory: ${cwd$3}. Run \`npm init -y\` to create one.`);
    process.exit(1);
  }

  const cmd = cliFlags['_'][2] || 'install';
  logger.debug(`run command: ${cmd}`); // Set this early -- before config loading -- so that plugins see it.

  if (cmd === 'build') {
    process.env.NODE_ENV = process.env.NODE_ENV || 'production';
  }

  if (cmd === 'dev') {
    process.env.NODE_ENV = process.env.NODE_ENV || 'development';
  }

  const config = loadAndValidateConfig(cliFlags, pkgManifest);
  logger.debug(`config loaded: ${util.format(config)}`);
  const lockfile = await readLockfile(cwd$3);
  logger.debug(`lockfile ${lockfile ? 'loaded.' : 'not loaded'}`);
  const commandOptions = {
    cwd: cwd$3,
    config,
    lockfile,
    pkgManifest,
    logger
  };

  if (cmd === 'add') {
    await addCommand(cliFlags['_'][3], commandOptions);
    return process.exit(0);
  }

  if (cmd === 'rm') {
    await rmCommand(cliFlags['_'][3], commandOptions);
    return process.exit(0);
  }

  if (cliFlags['_'].length > 3) {
    logger.error(`Unexpected multiple commands`);
    process.exit(1);
  }

  if (cmd === 'build') {
    await command$1(commandOptions);
    return process.exit(0);
  }

  if (cmd === 'dev') {
    await command$2(commandOptions);
    return process.exit(0);
  }

  if (cmd === 'install') {
    await command(commandOptions);
    return process.exit(0);
  }

  logger.error(`Unrecognized command: ${cmd}`);
  process.exit(1);
}

exports.cli = cli;
exports.createConfiguration = createConfiguration;
exports.unstable_installCommand = install;
//# sourceMappingURL=index.js.map
